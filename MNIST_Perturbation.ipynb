{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Perturbation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/infomon/understanding_cnn/blob/master/MNIST_Perturbation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eDTT8goRKgTh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Analyzers using Input Perturbations\n",
        "\n",
        "This notebook will guide you through an example of how to evaluate analyzers via perturbing the input according to the importance that the analysis method attribute to input regions.\n",
        "\n",
        "The input images are divided into quadratic regions that are sorted according to their importance w.r.t. to the pixel-wise saliency scores assigned by those analyzers. Then, the information content of the image is gradually destroyed by perturbation of the most important regions. The effect of this perturbation on the classifier performance is measured. This procedure is repeated several times.\n",
        "\n",
        "We expect that the classifier performance drops quickly if important information is removed and remains largely unaffected when perturbing unimportant regions.\n",
        "\n",
        "Thus, different analyzers can be compared by measuring how quickly their performance drops, i.e. the quicker the classifier performance drops after input perturbation w.r.t. to the prediction analysis, the better the analyzer is capable of identifying the input components responsible for the output of the model.\n",
        "\n",
        "Similarly, several models can be compared, e.g. with random perturbations on the data, towards their resilience to noisy input data: The faster the model prediction declines with ongoing perturbations, the more susceptible the classifier is to noise.\n",
        "\n",
        "Reference:\n",
        "\n",
        "*[Samek et al.](http://dx.doi.org/10.1109/TNNLS.2016.2599820)*, \"Evaluating the visualization of what a deep neural network has learned.\" *IEEE transactions on neural networks and learning systems* 28.11 (2017): 2660-2673.\n",
        "\n",
        "-----\n",
        "\n",
        "Parts of the code that do not contribute to the main focus are outsourced into utility modules. To learn more about the basic usage of **iNNvestigate** have look into this notebook: [Introduction to iNNvestigate](introduction.ipynb) and [Comparing methods on MNIST](mnist_method_comparison.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Dw0I9N7xNDMK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Import needed libraries**\n"
      ]
    },
    {
      "metadata": {
        "id": "71L84BBCzMS7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r understanding_cnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QkCym2H2NQXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "12da9062-4a8b-4041-afbc-6809d801728a"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/albermax/innvestigate\n",
        "!pip install -q deeplift\n",
        "!git clone https://github.com/infomon/understanding_cnn\n",
        "import shutil\n",
        "shutil.move(\"/content/understanding_cnn/utils/utils.py\", \"/content\")\n",
        "shutil.move(\"/content/understanding_cnn/utils/utils_mnist.py\", \"/content\")\n",
        "shutil.move(\"/content/understanding_cnn/models/pretrained_models/MNISTcnn.h5\", \"/content\")\n",
        "!rm -r understanding_cnn"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for innvestigate (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCloning into 'understanding_cnn'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 54 (delta 12), reused 42 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c_TiMdYqKgTl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "kJ88A1TJKgTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "43fc7a9d-54e2-4dae-cd84-1e19d94bb598"
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WjrFfjxMKgTr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "import imp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import keras\n",
        "import keras.backend\n",
        "import keras.models\n",
        "\n",
        "import innvestigate\n",
        "import innvestigate.utils as iutils\n",
        "\n",
        "from innvestigate.tools import Perturbation, PerturbationAnalysis\n",
        "\n",
        "try:\n",
        "    import cPickle as pickle\n",
        "except ImportError:  # python 3.x\n",
        "    import pickle\n",
        "    \n",
        "import json\n",
        "\n",
        "# Use utility libraries to focus on relevant iNNvestigate routines.\n",
        "eutils = imp.load_source(\"utils\", \"utils.py\")\n",
        "mnistutils = imp.load_source(\"utils_mnist\", \"utils_mnist.py\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X2KN1IaNKgTx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "Then, the MNIST data is loaded in its entirety, formatted according to the specifications of the Keras backend."
      ]
    },
    {
      "metadata": {
        "id": "d1Yzkpc9KgTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "96bc9849-f635-4f8e-e13f-a559d86e4e39"
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "# returns x_train, y_train, x_test, y_test as numpy.ndarray\n",
        "data_not_preprocessed = mnistutils.fetch_data()\n",
        "\n",
        "# Create preprocessing functions\n",
        "input_range = [-1, 1]\n",
        "preprocess, revert_preprocessing = mnistutils.create_preprocessing_f(data_not_preprocessed[0], input_range)\n",
        "\n",
        "# Preprocess data\n",
        "data = (\n",
        "    preprocess(data_not_preprocessed[0]), data_not_preprocessed[1],\n",
        "    preprocess(data_not_preprocessed[2]), data_not_preprocessed[3]\n",
        ")\n",
        "\n",
        "num_classes = len(np.unique(data[1]))\n",
        "label_to_class_name = [str(i) for i in range(num_classes)]\n",
        "\n",
        "x_test, y_test = data[2:]\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "test_sample = np.copy(x_test[0:1])\n",
        "generator = iutils.BatchSequence([x_test, y_test], batch_size=256)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mYjcDgFCKgT1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "c2Ix4slhKgT2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The next part trains and evaluates a CNN."
      ]
    },
    {
      "metadata": {
        "id": "2HHZWBqwKgT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "891eee94-67d6-4d5a-9c49-cfe320483d7a"
      },
      "cell_type": "code",
      "source": [
        "# Create & train model\n",
        "model = keras.models.load_model('MNISTcnn.h5')\n",
        "model.get_layer(name='dense_1').name = 'dense_1a'\n",
        "model.get_layer(name='conv2d_1').name = 'conv2d_1a'\n",
        "model.get_layer(name='conv2d_2').name = 'conv2d_2a'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bpBzwWAfKgT9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perturbation Analysis"
      ]
    },
    {
      "metadata": {
        "id": "IxdmbqSeKgUE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup analyzer and perturbation\n",
        "The perturbation analysis takes several parameters:\n",
        "* `perturbation_function`: This is the method with which the pixels in the most important regions are perturbated. You can pass your own function or pass a string to select one of the predefined functions, e.g. \"zeros\", \"mean\" or \"gaussian\".\n",
        "* `region_shape`: The shape of the regions that are considered for perturbation. In this case, we use single pixels. Regions are aggregated (\"pooled\") using a (customizable) aggregation function that is average pooling by default. The input image is padded such that it can be subdivided into an integer number of regions.\n",
        "* `steps`: Number of perturbation steps. \n",
        "* `regions_per_step`: In each perturbation step, the `regions_per_step` regions are perturbed.\n",
        "\n",
        "Feel free to play around with different analyzers, e.g. by selecting them from the `methods` list via `selected_methods_indices`."
      ]
    },
    {
      "metadata": {
        "id": "Sh8MyQ2WKgUP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Evaluate the model after several perturbation steps"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "r3z51k_SKgUF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "54c20301-d642-48f4-c6e6-bc4786862524"
      },
      "cell_type": "code",
      "source": [
        "perturbation_function = \"gaussian\"\n",
        "region_shape  = (7, 7) \n",
        "steps = 15\n",
        "regions_per_step = 1  # Perturbate 1 region per step\n",
        "\n",
        "# Scale to [0, 1] range for plotting.\n",
        "def input_postprocessing(X):\n",
        "    return revert_preprocessing(X) / 255\n",
        "\n",
        "noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
        "ri = input_range[0]  # reference input\n",
        "\n",
        "\n",
        "# Configure analysis methods and properties\n",
        "methods = [\n",
        "    # NAME                    OPT.PARAMS                POSTPROC FXN               TITLE\n",
        "    (\"random\",{},mnistutils.graymap,\"Random\"), #0\n",
        "    # Show input\n",
        "    (\"input\",                 {},                       input_postprocessing,      \"Input\"), #1\n",
        "\n",
        "    # Function\n",
        "    (\"gradient\",              {\"postprocess\": \"abs\"},   mnistutils.graymap,        \"Gradient\"), #2\n",
        "    (\"smoothgrad\",            {\"noise_scale\": noise_scale,\n",
        "                               \"postprocess\": \"square\"},mnistutils.graymap,        \"SmoothGrad\"), #3\n",
        "\n",
        "    # Signal\n",
        "    (\"deconvnet\",             {},                       mnistutils.bk_proj,        \"Deconvnet\"), #4\n",
        "    (\"guided_backprop\",       {},                       mnistutils.bk_proj,        \"Guided Backprop\",), #5\n",
        "    (\"pattern.net\",           {\"pattern_type\": \"relu\"}, mnistutils.bk_proj,        \"PatternNet\"), #6\n",
        "\n",
        "    # Interaction\n",
        "    (\"pattern.attribution\",   {\"pattern_type\": \"relu\"}, mnistutils.heatmap,        \"PatternAttribution\"), #7\n",
        "    (\"deep_taylor.bounded\",   {\"low\": input_range[0],\n",
        "                               \"high\": input_range[1]}, mnistutils.heatmap,        \"DeepTaylor\"), #8\n",
        "    (\"input_t_gradient\",      {},                       mnistutils.heatmap,        \"Input * Gradient\"), #9\n",
        "    (\"integrated_gradients\",  {\"reference_inputs\": ri}, mnistutils.heatmap,        \"Integrated Gradients\"), #10\n",
        "    (\"deep_lift.wrapper\",     {\"reference_inputs\": ri}, mnistutils.heatmap,        \"DeepLIFT Wrapper - Rescale\"), #11\n",
        "    (\"deep_lift.wrapper\",     {\"reference_inputs\": ri, \"nonlinear_mode\": \"reveal_cancel\"},\n",
        "                                                        mnistutils.heatmap,        \"DeepLIFT Wrapper - RevealCancel\"), #12\n",
        "    (\"lrp.z\",                 {},                       mnistutils.heatmap,        \"LRP-Z\"), #13\n",
        "    (\"lrp.epsilon\",           {\"epsilon\": 1},           mnistutils.heatmap,        \"LRP-Epsilon\"), #14\n",
        "    (\"lrp.epsilon_IB\",           {\"epsilon\": 1},           mnistutils.heatmap,        \"LRP-Epsilon\"), #14\n",
        "    (\"lrp.alpha_1_beta_0\",           {},           mnistutils.heatmap,        \"LRP-Alpha1-Beta0\"), #15\n",
        "    (\"lrp.alpha_1_beta_0_IB\",           {},           mnistutils.heatmap,        \"LRP-Alpha1-Beta0 IB\"), #16\n",
        "    (\"lrp.alpha_2_beta_1\",           {},           mnistutils.heatmap,        \"LRP-Alpha2-Beta1\"), #17\n",
        "    (\"lrp.alpha_2_beta_1_IB\",           {},           mnistutils.heatmap,        \"LRP-Alpha2-Beta1 IB\"), #18\n",
        "]\n",
        "\n",
        "# Select methods of your choice\n",
        "selected_methods_indices = [0,14,15,16,17,18,19]\n",
        "selected_methods = [methods[i] for i in selected_methods_indices]\n",
        "print('Using method(s) \"{}\".'.format([method[0] for method in selected_methods]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using method(s) \"['random', 'lrp.epsilon', 'lrp.epsilon_IB', 'lrp.alpha_1_beta_0', 'lrp.alpha_1_beta_0_IB', 'lrp.alpha_2_beta_1', 'lrp.alpha_2_beta_1_IB']\".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3DCNf6UxKgUJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The main loop below will now instantiate the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above."
      ]
    },
    {
      "metadata": {
        "id": "rNwdbgUXKgUL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create model without trailing softmax\n",
        "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)\n",
        "\n",
        "analyzers = [innvestigate.create_analyzer(method[0],\n",
        "                                        model_wo_softmax,\n",
        "                                        **method[1]) for method in selected_methods]\n",
        "for analyzer in analyzers:\n",
        "    analyzer.fit(data[0],\n",
        "                 batch_size=1, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOlSvrX3KgUQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup perturbation\n",
        "The perturbation analysis consists of two parts:\n",
        "1. An object of the class `Perturbation` that performs the actual perturbation of input images. Here, we use (2, 2)-regions (i.e. single pixels) and add Gaussian noise to the original values of the most important pixels.\n",
        "2. An object of the class `PerturbationAnalysis` that computes the analysis, performes several perturbation steps and evaluates the model performance. In each step, the 1% most important pixels are perturbed."
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "t-HAjBP8KgUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "1c85eafa-d2ca-418c-feb1-7d4721733310"
      },
      "cell_type": "code",
      "source": [
        "scores_selected_methods = dict()\n",
        "perturbation_analyses = list()\n",
        "for method, analyzer in zip(selected_methods, analyzers):\n",
        "    print(\"Method: {}\".format(method[0]))\n",
        "    \n",
        "    # Set up the perturbation analysis\n",
        "    perturbation = Perturbation(perturbation_function, region_shape=region_shape, in_place=False)\n",
        "    \n",
        "    # Comment out to invert the perturbation order\n",
        "    # perturbation.aggregation_function = lambda x, axis: -np.mean(x, axis=axis)\n",
        "    \n",
        "    perturbation_analysis = PerturbationAnalysis(analyzer, model, generator, perturbation, recompute_analysis=False,\n",
        "                                                steps=steps, regions_per_step=regions_per_step, verbose=True)\n",
        "    \n",
        "    scores = perturbation_analysis.compute_perturbation_analysis()\n",
        "    \n",
        "    # Store the scores and perturbation analyses for later use\n",
        "    scores_selected_methods[method[0]] = np.array(scores)\n",
        "    perturbation_analyses.append(perturbation_analysis)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Method: random\n",
            "Step 1 of 15: 1 regions perturbed. Time elapsed: 0.806 seconds.\n",
            "Step 2 of 15: 2 regions perturbed. Time elapsed: 1.004 seconds.\n",
            "Step 3 of 15: 3 regions perturbed. Time elapsed: 1.004 seconds.\n",
            "Step 4 of 15: 4 regions perturbed. Time elapsed: 1.104 seconds.\n",
            "Step 5 of 15: 5 regions perturbed. Time elapsed: 1.204 seconds.\n",
            "Step 6 of 15: 6 regions perturbed. Time elapsed: 1.410 seconds.\n",
            "Step 7 of 15: 7 regions perturbed. "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U1nmy_7DKgUV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plot the perturbation curves and compute area over the perturbation curve (AOPC)"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "yZD8E1yUKgUW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np.save(\"scores_selected_methods\",scores_selected_methods)\n",
        "with open('scores_selected_methods.p', 'wb') as fp:\n",
        "    pickle.dump(scores_selected_methods, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "#with open('scores_selected_methods.json', 'w') as fp:\n",
        "#    json.dump(scores_selected_methods, fp, sort_keys=True, indent=4)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "linestyles = ['-', '--', '-.', ':']\n",
        "linestye_counter = 0\n",
        "aopc = list()  # Area over the perturbation curve\n",
        "baseline_accuracy = scores_selected_methods[\"random\"][:, 1]\n",
        "for method_name in scores_selected_methods.keys():\n",
        "    scores = scores_selected_methods[method_name]\n",
        "    accuracy = scores[:, 1]\n",
        "    aopc.append(accuracy[0] - np.mean(accuracy))\n",
        "    \n",
        "    label = \"{} (AOPC: {:.3f})\".format(method_name, aopc[-1])\n",
        "    plt.plot(accuracy - baseline_accuracy, label=label,\n",
        "             linestyle=linestyles[linestye_counter],\n",
        "             linewidth=3)\n",
        "    \n",
        "plt.xlabel(\"Perturbation steps\")\n",
        "plt.ylabel(\"Difference of accuracy to random analyzer\")\n",
        "plt.xticks(np.array(range(scores.shape[0])))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OwUvMkc1KgUb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As mentioned above, a steeper decrease shows a better identification of the relevant information."
      ]
    },
    {
      "metadata": {
        "id": "MYFpf3idKgUd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Plot perturbed sample\n",
        "Finally, we plot the perturbations on a selected test sample and show them along with the respective analyses."
      ]
    },
    {
      "metadata": {
        "id": "z5cpys3gKgUe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now plot the perturbation step by step.\n",
        "fig1 = plt.figure()\n",
        "fig1 = plt.gcf()\n",
        "grid, row_labels = [], []\n",
        "col_labels = [\"Input\", \"Analysis\", \"Ordering\"]+[\"Step {}\".format(i+1) for i in range(steps)]\n",
        "\n",
        "\n",
        "for perturbation_analysis, method in zip(perturbation_analyses, selected_methods):\n",
        "    row_labels.append([method[-1]])\n",
        "    samples = list()\n",
        "    \n",
        "    # Reset the perturbation_analysis\n",
        "    perturbation_analysis.perturbation.num_perturbed_regions = 1\n",
        "\n",
        "    sample = test_sample\n",
        "    analysis = perturbation_analysis.analyzer.analyze(sample)\n",
        "\n",
        "    # Divide into regions and order them according to their analysis score\n",
        "    # TODO backend channel ordering\n",
        "    aggregated_regions = perturbation_analysis.perturbation.reduce_function(np.moveaxis(analysis, 3, 1), axis=1, keepdims=True)\n",
        "    aggregated_regions = perturbation_analysis.perturbation.aggregate_regions(aggregated_regions)\n",
        "    ranks = perturbation_analysis.perturbation.compute_region_ordering(aggregated_regions)\n",
        "\n",
        "    # Perturbate for some steps\n",
        "    for i in range(steps+1):\n",
        "        # Plot the original image and analysis without any perturbation\n",
        "        if i > 0:\n",
        "            perturbation_analysis.perturbation.num_perturbed_regions += perturbation_analysis.regions_per_step\n",
        "            # Perturbate\n",
        "            sample = perturbation_analysis.compute_on_batch(sample, analysis)\n",
        "        # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
        "        sample_to_show = mnistutils.postprocess(sample.repeat(3, axis=-1))\n",
        "        analysis = mnistutils.postprocess(analysis)\n",
        "        # Apply analysis postprocessing, e.g., creating a heatmap.\n",
        "        sample_to_show = np.clip(input_postprocessing(sample_to_show), 0, 1)\n",
        "\n",
        "        samples.append(sample_to_show[0])    \n",
        "    # Plot analysis\n",
        "    analysis = method[2](analysis)\n",
        "    \n",
        "    # Add analysis and ranking\n",
        "    samples.insert(1, analysis[0])\n",
        "    samples.insert(2, -ranks[0][0])\n",
        "        \n",
        "    grid.append(samples)\n",
        "  \n",
        "eutils.plot_image_grid(grid, row_labels, list(), col_labels)\n",
        "plt.show()\n",
        "\n",
        "fig1.savefig('selectivityImgGradients.png', bbox_inches='tight')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}