{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compare networks on ImageNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/infomon/understanding_cnn/blob/master/Compare_networks_on_ImageNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DqkiiG7KSJVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compare networks on ImageNet"
      ]
    },
    {
      "metadata": {
        "id": "lVTelsQGSJVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook we show how one can use **iNNvestigate** to analyze the prediction of *different* ImageNet-models!\n",
        "\n",
        "This notebook is an extension of the [Comparing networks on ImagenNet](imagenet_network_comparison.ipynb) notebook.\n"
      ]
    },
    {
      "metadata": {
        "id": "gCSz5J_iSJVQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Innvestigate Toolbox is installed. The toolbox contains multiple visualization methods being used in this experiment.\n",
        "Also some needed helper files are clone from the understanding_cnn repository. The whole folder is removed, after moving all needed helpers to the /content/ directory"
      ]
    },
    {
      "metadata": {
        "id": "NFCz2fStSNX2",
        "colab_type": "code",
        "outputId": "b80a43d9-5ad8-4c44-bcd2-e10da25823bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/albermax/innvestigate\n",
        "!pip install -q deeplift\n",
        "!git clone https://github.com/infomon/understanding_cnn\n",
        "  \n",
        "import shutil\n",
        "import os\n",
        "if not os.path.isfile(\"utils.py\"):\n",
        "  shutil.move(\"/content/understanding_cnn/utils/utils.py\", \"/content\")\n",
        "if not os.path.isfile(\"utils_imagenet.py\"):\n",
        "  shutil.move(\"/content/understanding_cnn/utils/utils_imagenet.py\", \"/content\")\n",
        "if not os.path.isdir(\"models\"):\n",
        "  shutil.move(\"/content/understanding_cnn/models\", \"/content\")\n",
        "if not os.path.isdir(\"images\"):\n",
        "  shutil.move(\"/content/understanding_cnn/data/images\", \"/content\")\n",
        "if not os.path.isfile(\"data_loader.py\"):\n",
        "  shutil.move(\"/content/understanding_cnn/data/data_loader.py\", \"/content\")\n",
        "  \n",
        "!rm -r understanding_cnn\n",
        "\n",
        "!pip install scipy==1.2.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for innvestigate (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCloning into 'understanding_cnn'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 117 (delta 45), reused 74 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (117/117), 15.23 MiB | 27.23 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "Requirement already satisfied: scipy==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FYmqnPrvSJVV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4f55ef16-4b2e-41e4-e3b9-8777f4a3513b"
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kvP2z9aeSJVk",
        "colab_type": "code",
        "outputId": "03430b74-86c1-41f6-cfa8-ba25b570fad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "import imp\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import keras\n",
        "import keras.backend\n",
        "import keras.models\n",
        "\n",
        "import innvestigate\n",
        "import innvestigate.applications.imagenet\n",
        "import innvestigate.utils as iutils\n",
        "\n",
        "import models.model_loader as model_loader\n",
        "import data_loader\n",
        "\n",
        "# Use utility libraries to focus on relevant iNNvestigate routines.\n",
        "eutils = imp.load_source(\"utils\", \"utils.py\")\n",
        "imgnetutils = imp.load_source(\"utils_imagenet\", \"utils_imagenet.py\")\n",
        "\n",
        "# We create many graphs, let's not run out of memory.\n",
        "if keras.backend.backend() == \"tensorflow\":\n",
        "    config = keras.backend.tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    keras.backend.set_session(keras.backend.tf.Session(config=config))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d1041e01abf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minnvestigate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_loader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/model_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minnvestigate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils_imagenet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m __all__ = [\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.utils_imagenet'; 'utils' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RFbx3_V-SJV-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models, data and analyzers"
      ]
    },
    {
      "metadata": {
        "id": "jKt7AuA1SJWC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We choose a set of ImageNet models:"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "RelTe1AQSJWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Choose a list of models\n",
        "netnames = [\n",
        "    # NAME                  MODEL LOADER\n",
        "    #[\"AlexNet\",             model_loader.AlexNet],\n",
        "    [\"VGG19\",               model_loader.VGG19],\n",
        "    [\"Inception_v3\",        model_loader.Inception_v3],\n",
        "    [\"Inception_Resnet_v2\", model_loader.Inception_Resnet_v2],\n",
        "    [\"Resnet_v2_152\",       model_loader.Resnet_v2_152],\n",
        "    [\"ResNeXt_101\",         model_loader.Resnet_v1_101]\n",
        "]          \n",
        "n_nets = len(netnames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIhz5BB7SJWY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following function will load a specific model, load the data in the respective format and create analyzers for this model.\n",
        "\n",
        "**For a better understanding of this part we refer to the [Comparing networks on ImagenNet](imagenet_network_comparison.ipynb) notebook, from which this code segment is adopted from.**"
      ]
    },
    {
      "metadata": {
        "id": "TgXdS-dMSJWe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_model_data_and_analyzers(loader):\n",
        "    # Load the model definition.\n",
        "    model = loader()\n",
        "\n",
        "    # Get some example test set images.\n",
        "    data = data_loader.load_from_folder(\"images\",model.get_image_size())\n",
        "\n",
        "    \n",
        "    images = [] \n",
        "    label_to_class_name = []\n",
        "    for img,label in data:\n",
        "      images.append(img)\n",
        "      label_to_class_name.append(label)\n",
        "      \n",
        "    \n",
        "    patterns = model.get_patterns()\n",
        "    input_range = (-1,1)\n",
        "\n",
        "    noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
        "\n",
        "    # Methods we use and some properties.\n",
        "    methods = [\n",
        "        # NAME                    OPT.PARAMS                POSTPROC FXN                TITLE\n",
        "        # Show input.\n",
        "        (\"input\",                 {},                       imgnetutils.image,         \"Input\"), #0\n",
        "\n",
        "        # Function\n",
        "        (\"gradient\",              {\"postprocess\": \"abs\"},   imgnetutils.graymap,       \"Gradient\"), #1\n",
        "        (\"smoothgrad\",            {\"augment_by_n\": 16,\n",
        "                                   \"noise_scale\": noise_scale,\n",
        "                                   \"postprocess\": \"square\"},imgnetutils.graymap,       \"SmoothGrad\"), #2\n",
        "\n",
        "        # Signal\n",
        "        (\"deconvnet\",             {},                       imgnetutils.bk_proj,       \"Deconvnet\"), #3\n",
        "        (\"guided_backprop\",       {},                       imgnetutils.bk_proj,       \"Guided Backprop\",), #4\n",
        "        (\"pattern.net\",           {\"patterns\": patterns},   imgnetutils.bk_proj,       \"PatternNet\"), #5\n",
        "\n",
        "        # Interaction\n",
        "        (\"pattern.attribution\",   {\"patterns\": patterns},   imgnetutils.heatmap,       \"PatternAttribution\"), #6\n",
        "        (\"deep_taylor.bounded\",   {\"low\": input_range[0],\n",
        "                                   \"high\": input_range[1]}, imgnetutils.heatmap,       \"DeepTaylor\"), #7\n",
        "        (\"input_t_gradient\",      {},                       imgnetutils.heatmap,       \"Input * Gradient\"), #8\n",
        "        (\"integrated_gradients\",  {\"reference_inputs\": input_range[0],\n",
        "                                   \"steps\": 16},            imgnetutils.heatmap,       \"Integrated Gradients\"), #9\n",
        "        (\"lrp.epsilon\",           {\"epsilon\": 1},           imgnetutils.heatmap,        \"LRP-Epsilon\"), #10\n",
        "        (\"lrp.epsilon_IB\",           {\"epsilon\": 1},           imgnetutils.heatmap,        \"LRP-Epsilon IB\"), #11\n",
        "        (\"lrp.alpha_1_beta_0\",           {},           imgnetutils.heatmap,        \"LRP-Alpha1-Beta0\"), #12\n",
        "        (\"lrp.alpha_1_beta_0_IB\",           {},           imgnetutils.heatmap,        \"LRP-Alpha1-Beta0 IB\"), #13\n",
        "        (\"lrp.alpha_2_beta_1\",           {},           imgnetutils.heatmap,        \"LRP-Alpha2-Beta1\"), #14\n",
        "        (\"lrp.alpha_2_beta_1_IB\",           {},           imgnetutils.heatmap,        \"LRP-Alpha2-Beta1 IB\"), #15\n",
        "        (\"lrp.sequential_preset_a_flat\",{\"epsilon\": 1},     imgnetutils.heatmap,       \"LRP-PresetAFlat\"), #16 \n",
        "        (\"lrp.sequential_preset_b_flat\",{\"epsilon\": 1},     imgnetutils.heatmap,       \"LRP-PresetBFlat\"), #17\n",
        "    ]\n",
        "    \n",
        "    # Select methods of your choice\n",
        "    selected_methods_indices = [0,1,6,7,8,11,12,13,14,15]\n",
        "    selected_methods = [methods[i] for i in selected_methods_indices]\n",
        "    print('Using method(s) \"{}\".'.format([method[0] for method in selected_methods]))\n",
        "    \n",
        "    # Create model without trailing softmax\n",
        "    model_wo_softmax = model.get_model()\n",
        "\n",
        "    # Create analyzers.\n",
        "    analyzers = []\n",
        "    for method in selected_methods:\n",
        "        try:\n",
        "            analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
        "                                                    model_wo_softmax, # model without softmax output\n",
        "                                                    **method[1])      # optional analysis parameters\n",
        "        except innvestigate.NotAnalyzeableModelException:\n",
        "            # Not all methods work with all models.\n",
        "            analyzer = None\n",
        "            print(method[3]+\" cannot be used!\")\n",
        "        analyzers.append(analyzer)\n",
        "        \n",
        "    return (images, label_to_class_name,\n",
        "            selected_methods, model, model_wo_softmax, analyzers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtwwGzixSJWt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ]
    },
    {
      "metadata": {
        "id": "1XaJHM3HSJWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we analyze each image with the different networks and different analyzers:"
      ]
    },
    {
      "metadata": {
        "id": "c4iOXexXSJW3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "analyses = {}\n",
        "texts = {}\n",
        "    \n",
        "for (netname,loader) in netnames:\n",
        "    print(\"Creating analyses for network {}.\".format(netname))\n",
        "    tmp = prepare_model_data_and_analyzers(loader)\n",
        "    (images, label_to_class_name,\n",
        "     methods, model, model_wo_softmax, analyzers) = tmp\n",
        "    \n",
        "    analysis = np.zeros([len(images), len(analyzers)]+list(model.get_image_size())+[3])\n",
        "    text = []\n",
        "    \n",
        "    channels_first = keras.backend.image_data_format() == \"channels_first\"\n",
        "    color_conversion = \"BGRtoRGB\" if model.get_color_coding() == \"BGR\" else None\n",
        "\n",
        "    for i, x in enumerate(images):\n",
        "        # Add batch axis.\n",
        "        x_pp = model.preprocess_input(x)\n",
        "\n",
        "        # Predict final activations, probabilites, and label.\n",
        "        presm = model.predict_wo_softmax(x_pp)[0]\n",
        "        prob = model.predict_with_softmax(x_pp)[0]\n",
        "        y_hat = prob.argmax()\n",
        "\n",
        "        # Save prediction info:\n",
        "        text.append((\"%s\" % label_to_class_name[i],    # ground truth label\n",
        "                     \"%.2f\" % presm.max(),             # pre-softmax logits\n",
        "                     \"%.2f\" % prob.max(),              # probabilistic softmax output  \n",
        "                     \"%s\" % model.decode_predictions(prob[None,...], top=1)[0][1] # predicted label\n",
        "                    ))\n",
        "\n",
        "        for aidx, analyzer in enumerate(analyzers):\n",
        "            print(methods[aidx][0]+\" for image with label \"+label_to_class_name[i])\n",
        "            if methods[aidx][0] == \"input\":\n",
        "                # Do not analyze, but keep not preprocessed input.\n",
        "                a = x / 255\n",
        "            elif analyzer:\n",
        "                # Analyze.\n",
        "                a = analyzer.analyze(x_pp)\n",
        "\n",
        "                # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
        "                a = imgnetutils.postprocess(a, color_conversion, channels_first)\n",
        "                # Apply analysis postprocessing, e.g., creating a heatmap.\n",
        "                a = methods[aidx][2](a)\n",
        "            else:\n",
        "                a = np.zeros_like(x)\n",
        "            # Store the analysis.\n",
        "            analysis[i, aidx] = a[0]\n",
        "\n",
        "        analyses[netname] = analysis\n",
        "        texts[netname] = text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2auNo1OSJXO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we visualize the analysis results:"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "YxSYIxbFSJXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_images = analyses[netnames[0][0]].shape[0]\n",
        "\n",
        "# Prepare common labels\n",
        "col_labels = [''.join(method[3]) for method in methods]\n",
        "\n",
        "for image_index in range(n_images):\n",
        "    grid = []\n",
        "    row_labels_left = []\n",
        "    row_labels_right = []\n",
        "    \n",
        "    for netname,_ in netnames:\n",
        "        analysis, text = analyses[netname], texts[netname]\n",
        "        # Prepare the grid as rectengular list\n",
        "        grid.append([analysis[image_index, j] for j in range(analysis.shape[1])])\n",
        "        # Prepare the labels\n",
        "        label, presm, prob, pred = zip(*text)\n",
        "        label = label[image_index]\n",
        "        row_labels_left.append(('network: {}'.format(netname),'pred: {}'.format(pred[image_index])))\n",
        "        row_labels_right.append(('logit: {}'.format(presm[image_index]),'prob: {}'.format(prob[image_index])))\n",
        "\n",
        "    # Plot the analysis.\n",
        "    print(\"Image nr. {}, true label: {}\".format(image_index, label))\n",
        "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels,\n",
        "                           file_name=os.environ.get(\"plot_file_name\", None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "quYd1UlzSJXt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This figures show the analysis regarding the *actually predicted* class as computed by the selected analyzers. Each column shows the visualized results for different analyzers and each row shows the analyses wrt to one input sample. To the left of each row, the ground truth label `label` and the predicted label `pred` are show. To the right, the model's probabilistic (softmax) output is shown as `prob` and the logit output just before the terminating softmax layer as `logit`. Note that all analyses have been performed based on the logit output (layer)."
      ]
    }
  ]
}