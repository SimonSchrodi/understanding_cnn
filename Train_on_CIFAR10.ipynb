{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train on CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/infomon/understanding_cnn/blob/master/Train_on_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FZMBvA6pE5LP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "KPQkbwl2EqDR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, BatchNormalization\n",
        "from keras.layers import Lambda, MaxPooling2D, Input,AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "if K.backend() != 'tensorflow':\n",
        "    raise RuntimeError('This example can only run with the '\n",
        "                       'TensorFlow backend, '\n",
        "                       'because it requires TF-native augmentation APIs')\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "94xEIcobFAE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ]
    },
    {
      "metadata": {
        "id": "jTEAdkizFBqm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 200\n",
        "num_predictions = 20\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "subtract_pixel_mean = True # Subtracting pixel mean improves accuracy\n",
        "n = 12\n",
        "depth = n * 9 + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrR6yND8E7RJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Augmentation"
      ]
    },
    {
      "metadata": {
        "id": "gcvdhfB3EuMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment_2d(inputs, rotation=0, horizontal_flip=False, vertical_flip=False):\n",
        "    \"\"\"Apply additive augmentation on 2D data.\n",
        "\n",
        "    # Arguments\n",
        "      rotation: A float, the degree range for rotation (0 <= rotation < 180),\n",
        "          e.g. 3 for random image rotation between (-3.0, 3.0).\n",
        "      horizontal_flip: A boolean, whether to allow random horizontal flip,\n",
        "          e.g. true for 50% possibility to flip image horizontally.\n",
        "      vertical_flip: A boolean, whether to allow random vertical flip,\n",
        "          e.g. true for 50% possibility to flip image vertically.\n",
        "\n",
        "    # Returns\n",
        "      input data after augmentation, whose shape is the same as its original.\n",
        "    \"\"\"\n",
        "    if inputs.dtype != tf.float32:\n",
        "        inputs = tf.image.convert_image_dtype(inputs, dtype=tf.float32)\n",
        "\n",
        "    with tf.name_scope('augmentation'):\n",
        "        shp = tf.shape(inputs)\n",
        "        batch_size, height, width = shp[0], shp[1], shp[2]\n",
        "        width = tf.cast(width, tf.float32)\n",
        "        height = tf.cast(height, tf.float32)\n",
        "\n",
        "        transforms = []\n",
        "        identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\n",
        "\n",
        "        if rotation > 0:\n",
        "            angle_rad = rotation * 3.141592653589793 / 180.0\n",
        "            angles = tf.random_uniform([batch_size], -angle_rad, angle_rad)\n",
        "            f = tf.contrib.image.angles_to_projective_transforms(angles,\n",
        "                                                                 height, width)\n",
        "            transforms.append(f)\n",
        "\n",
        "        if horizontal_flip:\n",
        "            coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
        "            shape = [-1., 0., width, 0., 1., 0., 0., 0.]\n",
        "            flip_transform = tf.convert_to_tensor(shape, dtype=tf.float32)\n",
        "            flip = tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1])\n",
        "            noflip = tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])\n",
        "            transforms.append(tf.where(coin, flip, noflip))\n",
        "\n",
        "        if vertical_flip:\n",
        "            coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
        "            shape = [1., 0., 0., 0., -1., height, 0., 0.]\n",
        "            flip_transform = tf.convert_to_tensor(shape, dtype=tf.float32)\n",
        "            flip = tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1])\n",
        "            noflip = tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])\n",
        "            transforms.append(tf.where(coin, flip, noflip))\n",
        "\n",
        "    if transforms:\n",
        "        f = tf.contrib.image.compose_transforms(*transforms)\n",
        "        inputs = tf.contrib.image.transform(inputs, f, interpolation='BILINEAR')\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDNkfLnoGD8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ]
    },
    {
      "metadata": {
        "id": "lx5Qo0GFGFbh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "    \n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNR5u86jFK8a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ]
    },
    {
      "metadata": {
        "id": "OlNBDyD8KoOh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdKMMD6GKsyZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87r4ETEAFM2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f337a815-c173-4026-d699-decea61acb42"
      },
      "cell_type": "code",
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "  \n",
        "model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "  \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YvMuZLzjFi77",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "YJD1IHHIHP6l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "class TimeHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WcZUd_--FnN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1566
        },
        "outputId": "8744b11c-53fe-44c9-ab27-2562166c4c92"
      },
      "cell_type": "code",
      "source": [
        "csv_logger = CSVLogger('/content/training.log')\n",
        "time_callback = TimeHistory()\n",
        "tensor_board = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "checkpoint = ModelCheckpoint(model_name, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [csv_logger, time_callback, tensor_board, checkpoint]\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=callbacks_list,\n",
        "          shuffle=True)\n",
        "\n",
        "times = time_callback.times\n",
        "print(times)\n",
        "np.save(\"training_time.npy\",times)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "50000/50000 [==============================] - 695s 14ms/step - loss: 2.3412 - acc: 0.5261 - val_loss: 2.0419 - val_acc: 0.4935\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.49350, saving model to keras_cifar10_trained_model.h5\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 663s 13ms/step - loss: 1.4408 - acc: 0.6674 - val_loss: 1.4442 - val_acc: 0.6567\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.49350 to 0.65670, saving model to keras_cifar10_trained_model.h5\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 659s 13ms/step - loss: 1.2005 - acc: 0.7258 - val_loss: 1.5134 - val_acc: 0.6319\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.65670\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 660s 13ms/step - loss: 1.0690 - acc: 0.7594 - val_loss: 1.0935 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.65670 to 0.75090, saving model to keras_cifar10_trained_model.h5\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 658s 13ms/step - loss: 0.9802 - acc: 0.7839 - val_loss: 1.2143 - val_acc: 0.7015\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.75090\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 666s 13ms/step - loss: 0.9113 - acc: 0.8033 - val_loss: 1.1382 - val_acc: 0.7191\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.75090\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 667s 13ms/step - loss: 0.8544 - acc: 0.8203 - val_loss: 1.0878 - val_acc: 0.7452\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.75090\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 667s 13ms/step - loss: 0.8131 - acc: 0.8320 - val_loss: 0.9803 - val_acc: 0.7768\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.75090 to 0.77680, saving model to keras_cifar10_trained_model.h5\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 664s 13ms/step - loss: 0.7721 - acc: 0.8431 - val_loss: 1.0007 - val_acc: 0.7692\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.77680\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 659s 13ms/step - loss: 0.7441 - acc: 0.8520 - val_loss: 1.1239 - val_acc: 0.7421\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.77680\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 661s 13ms/step - loss: 0.7158 - acc: 0.8601 - val_loss: 1.2110 - val_acc: 0.6966\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.77680\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 655s 13ms/step - loss: 0.6917 - acc: 0.8676 - val_loss: 1.0477 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.77680\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 656s 13ms/step - loss: 0.6679 - acc: 0.8746 - val_loss: 1.0052 - val_acc: 0.7786\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.77680 to 0.77860, saving model to keras_cifar10_trained_model.h5\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 657s 13ms/step - loss: 0.6484 - acc: 0.8817 - val_loss: 1.0863 - val_acc: 0.7742\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.77860\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 658s 13ms/step - loss: 0.6309 - acc: 0.8869 - val_loss: 1.3512 - val_acc: 0.7304\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.77860\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 656s 13ms/step - loss: 0.6162 - acc: 0.8934 - val_loss: 1.2625 - val_acc: 0.7411\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.77860\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 656s 13ms/step - loss: 0.6050 - acc: 0.8978 - val_loss: 0.9125 - val_acc: 0.8043\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.77860 to 0.80430, saving model to keras_cifar10_trained_model.h5\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 657s 13ms/step - loss: 0.5916 - acc: 0.8997 - val_loss: 0.9760 - val_acc: 0.7912\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80430\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 658s 13ms/step - loss: 0.5878 - acc: 0.9025 - val_loss: 1.0317 - val_acc: 0.7837\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80430\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 657s 13ms/step - loss: 0.5788 - acc: 0.9060 - val_loss: 1.0261 - val_acc: 0.7886\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80430\n",
            "Epoch 21/200\n",
            "31200/50000 [=================>............] - ETA: 3:57 - loss: 0.5461 - acc: 0.9180"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}