{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Continuity Explanation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/infomon/understanding-cnn/blob/master/Continuity_Explanation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "65QbuEEk5cek",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Analyzers using\n",
        "This notebook will provide an example how to evaluate analyzers via translation of images.\n",
        "\n",
        "The notebook is based on the following axiom:\n",
        "Assuming the prediction function $f(x)$ is continious, then if two data points are nearly equivalent, then the explanations of their predictions should also be nearly equivalent.([Montavon et. al., 2018](https://reader.elsevier.com/reader/sd/pii/S1051200417302385?token=56EDF10BC4B2EE334D439DCD801F981B5B6953A2F821EA0CB38175B370AFF0BD8689F4CDD8411FF2E2D9CC997C533C46))\n",
        "Explanation continuity (or lack of it) can be quantified by looking for the strongest variation of the explanation $R(x)$ in the input domain. This is called SVE (**S**trongest **V**ariation of **E**xplanation)\n",
        "\n",
        "\\begin{equation}\n",
        "SVE=\\max_{x \\neq x'} \\frac{\\lVert R(x) - R(x') \\lVert_1}{\\lVert x - x' \\lVert_2}\n",
        "\\end{equation}\n",
        "\n",
        "If the technique satisfies explanation continuity, the explanations produced also must change continuously without sudden jumps.\n",
        "Also a lower SVE indicates that the continuity holds for the given analyzer.\n",
        "\n",
        "For a qualitative analysis a input image is translated horizontally from left to right. Then, for every translated image the prediction is saved and afterwards plotted into a diagram.\n",
        "\n",
        "The analyzers used are based on the implementation of the [iNNvestigate Toolbox](https://arxiv.org/abs/1808.04260)"
      ]
    },
    {
      "metadata": {
        "id": "QLvBI_yu9wR6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install iNNvestigate Toolbox"
      ]
    },
    {
      "metadata": {
        "id": "vdnY3Fp65QTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/albermax/innvestigate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IM97R9MC-KbJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "7B16w01g-MZq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVnJRFZj-Tiz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "import innvestigate\n",
        "import innvestigate.utils as iutils\n",
        "\n",
        "import utils_mnist as mnistutils\n",
        "\n",
        "import data_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "poeDzK4C-seI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "Then, the MNIST data is loaded in its entirety, formatted according to the specifications of the Keras backend."
      ]
    },
    {
      "metadata": {
        "id": "6tovqWRF-tjZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load data\n",
        "data_not_preprocessed = data_loader.fetch_mnist_data()\n",
        "\n",
        "#create reprocessing functions\n",
        "input_range = [-1,1]\n",
        "preprocess, revert_preprocessing = mnistutils.create_preprocessing_f(data_not_preprocessed[0], input_range)\n",
        "\n",
        "#preprocess data\n",
        "data = (\n",
        "    preprocess(data_not_preprocessed[0]), data_not_preprocessed[1],\n",
        "    preprocess(data_not_preprocessed[2]), data_not_preprocessed[3]\n",
        ")\n",
        "\n",
        "n = 10\n",
        "test_images = list(zip(data[2][:n], data[3][:n]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pnETasf6_IrD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "The next part loads are pretained CNN on MNIST and a \"softmax-less\" model is generated."
      ]
    },
    {
      "metadata": {
        "id": "nOGIkCwv_Zfs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model('models/pretrained_models/MNISTcnn.h5')\n",
        "model.get_layer(name='dense_1').name='dense_1a'\n",
        "model.get_layer(name='conv2d_1').name = 'conv2d_1a'\n",
        "model.get_layer(name='conv2d_2').name = 'conv2d_2a'\n",
        "\n",
        "#create momdel without trailing softmax\n",
        "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZEO31vEZ_wWk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup analyzers"
      ]
    },
    {
      "metadata": {
        "id": "BwP1zl8V_1Jc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noise_scale = (input_range[1] - input_range[0]) * 0.1\n",
        "ri = input_range[0]  # reference input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LvY2q46F_8FL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Configure analysis methods and properties\n",
        "methods = [\n",
        "    # NAME                    OPT.PARAMS                POSTPROC FXN               TITLE\n",
        "\n",
        "    # Function\n",
        "    (\"gradient\", {\"postprocess\": \"abs\"}, mnistutils.graymap, \"Gradient\"),  # 0\n",
        "    (\"smoothgrad\", {\"noise_scale\": noise_scale,\n",
        "                    \"postprocess\": \"square\"}, mnistutils.graymap, \"SmoothGrad\"),  # 1\n",
        "\n",
        "    # Signal\n",
        "    (\"deconvnet\", {}, mnistutils.bk_proj, \"Deconvnet\"),  # 2\n",
        "    (\"guided_backprop\", {}, mnistutils.bk_proj, \"Guided Backprop\",),  # 3\n",
        "    (\"pattern.net\", {\"pattern_type\": \"relu\"}, mnistutils.bk_proj, \"PatternNet\"),  # 4\n",
        "\n",
        "    # Interaction\n",
        "    (\"pattern.attribution\", {\"pattern_type\": \"relu\"}, mnistutils.heatmap, \"PatternAttribution\"),  # 5\n",
        "    (\"deep_taylor.bounded\", {\"low\": input_range[0],\n",
        "                                 \"high\": input_range[1]}, mnistutils.heatmap, \"DeepTaylor\"),  # 6\n",
        "    (\"input_t_gradient\", {}, mnistutils.heatmap, \"Input * Gradient\"),  # 7\n",
        "    (\"integrated_gradients\", {\"reference_inputs\": ri}, mnistutils.heatmap, \"Integrated Gradients\"),  # 8\n",
        "    (\"lrp.z\", {}, mnistutils.heatmap, \"LRP-Z\"),  # 9\n",
        "    (\"lrp.epsilon\", {\"epsilon\": 1}, mnistutils.heatmap, \"LRP-Epsilon\"),  # 10\n",
        "    (\"lrp.epsilon_IB\", {\"epsilon\": 1}, mnistutils.heatmap, \"LRP-Epsilon\"),  # 11\n",
        "    (\"lrp.alpha_1_beta_0\", {}, mnistutils.heatmap, \"LRP-Alpha1-Beta0\"),  # 12\n",
        "    (\"lrp.alpha_1_beta_0_IB\", {}, mnistutils.heatmap, \"LRP-Alpha1-Beta0 IB\"),  # 13\n",
        "    (\"lrp.alpha_2_beta_1\", {}, mnistutils.heatmap, \"LRP-Alpha2-Beta1\"),  # 14\n",
        "    (\"lrp.alpha_2_beta_1_IB\", {}, mnistutils.heatmap, \"LRP-Alpha2-Beta1 IB\"),  # 15\n",
        "    ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5v0rKQK7Ae8E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Select methods of your choice\n",
        "selected_methods_indices = [19]\n",
        "selected_methods = [methods[i] for i in selected_methods_indices]\n",
        "print('Using method(s) \"{}\".'.format([method[0] for method in selected_methods]))\n",
        "methods = selected_methods"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "86IZBgkgAlLt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "analyzers = []\n",
        "for method in methods:\n",
        "    analyzer = innvestigate.create_analyzer(method[0],  # analysis method identifier\n",
        "                                            model_wo_softmax,  # model without softmax output\n",
        "                                            **method[1])  # optional analysis parameters\n",
        "\n",
        "    # Some analyzers require training.\n",
        "    analyzer.fit(data[0], batch_size=256, verbose=1)\n",
        "    analyzers.append(analyzer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MVuIgFAfA61v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Translation of images"
      ]
    },
    {
      "metadata": {
        "id": "46qz-6h-A-JB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "translated_images = []\n",
        "dist = 20\n",
        "for i,(test_image, label) in enumerate(test_images):\n",
        "    test_image = np.stack((test_image,) * 3, axis=-1)\n",
        "    test_image = np.reshape(test_image,(28,28,3))\n",
        "\n",
        "    translated_images.append([])\n",
        "    tmp = []\n",
        "    M = np.float32([[1, 0, 1], [0, 1, 0]])\n",
        "    for j in range(-dist, dist + 1):\n",
        "        M[0,2] = j\n",
        "        translated_image = cv2.warpAffine(test_image, M, (28, 28))\n",
        "        translated_image = translated_image[:, :, 0]\n",
        "        translated_image = np.reshape(translated_image,(28,28,1))\n",
        "        tmp.append([translated_image,label])\n",
        "    translated_images[i] = tmp\n",
        "\n",
        "test_images = translated_images\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZdc2LX8BOYN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run analysis"
      ]
    },
    {
      "metadata": {
        "id": "iP_fOrY6BSR7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nof_test_images = len(test_images) * 2 * dist + 1\n",
        "preds = np.zeros((n,2 * dist + 1))\n",
        "analysis = np.zeros([n, 2 * dist + 1, len(analyzers), 28, 28, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UtciaZYbBaLC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for j in range(n):\n",
        "    for i, (x,y) in enumerate(test_images[j]):\n",
        "        # Add batch axis.\n",
        "        x = x[None, :, :, :]\n",
        "        \n",
        "        # Predict final activations, probabilites, and label.\n",
        "        presm = model_wo_softmax.predict_on_batch(x)[0]\n",
        "        prob = model.predict_on_batch(x)[0]\n",
        "        preds[j, i] = prob[y]\n",
        "\n",
        "        for aidx, analyzer in enumerate(analyzers):\n",
        "            # Analyze.\n",
        "            a = analyzer.analyze(x, neuron_selection=int(y))\n",
        "            \n",
        "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
        "            a = mnistutils.postprocess(a)\n",
        "            analysis[j, i, aidx] = a[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XfkzbJc6BoBC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create visualization"
      ]
    },
    {
      "metadata": {
        "id": "TqFiz7JqBsoG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = list(range(-dist,dist+1))\n",
        "avg_preds = np.zeros(2*dist + 1)\n",
        "for i in range(2*dist + 1):\n",
        "    avg_preds[i] = np.average(preds[:,i])\n",
        "\n",
        "avg_analysis = np.zeros([len(analyzers), 2 * dist + 1])\n",
        "for aidx, _ in enumerate(analyzers):\n",
        "    for i in range(2 * dist + 1):\n",
        "        avg_analysis[aidx, i] = np.average(analysis[0,i, aidx, :, :, :])  # Prepare the grid as rectengular list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yvoJXEDkB2Dm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel('horizontal translation in pixels')\n",
        "label = \"Prediction f(x)\"\n",
        "axlegend =ax1.plot(x, avg_preds, label=label, color=\"tab:blue\")\n",
        "ax1.tick_params(axis='y', bottom=False, top=False, labelbottom=False, which='both', length=0)\n",
        "ax1.set_yticklabels([])\n",
        "\n",
        "twin_ax = []\n",
        "helper_axes = []\n",
        "linestyles = ['--', '-.', ':',(0, (5, 1)),(0, (3, 5, 1, 5)),(0, (3, 1, 1, 1, 1, 1))]\n",
        "colors = [\"green\", \"red\", \"magenta\", \"cyan\", \"brown\", \"orange\"]\n",
        "for aidx,method_name in enumerate(selected_methods):\n",
        "    twin_ax.append(ax1.twinx())\n",
        "    twin_ax[aidx].tick_params(axis='y', bottom=False, top=False, labelbottom=False, which='both', length=0)\n",
        "    twin_ax[aidx].set_yticklabels([])\n",
        "    label = \"{} R(x)\".format(method_name[3])\n",
        "    helper_axes.append(twin_ax[aidx].plot(x, avg_analysis[aidx], label=label, linestyle=linestyles[aidx], color=colors[aidx]))\n",
        "\n",
        "lns = axlegend\n",
        "for tmp in helper_axes:\n",
        "   lns = lns + tmp\n",
        "labs = [l.get_label() for l in lns]\n",
        "ax1.legend(lns, labs)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}