{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compare networks on ImageNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/infomon/understanding_cnn/blob/master/Compare_networks_on_ImageNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DqkiiG7KSJVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compare networks on ImageNet"
      ]
    },
    {
      "metadata": {
        "id": "lVTelsQGSJVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook we show how one can use **iNNvestigate** to analyze the prediction of *different* ImageNet-models!\n",
        "\n",
        "This notebook is an extension of the [Comparing networks on ImagenNet](imagenet_network_comparison.ipynb) notebook.\n",
        "\n",
        "-----\n",
        "\n",
        "\n",
        "Note this script is fairly slow, because we are rebuilding models times analysis methods many computational graphs.\n",
        "\n",
        "-----\n",
        "\n",
        "**To use this notebook please download the example images using the following script:**\n",
        "\n",
        "`innvestigate/examples/images/wget_imagenet_2011_samples.sh`"
      ]
    },
    {
      "metadata": {
        "id": "gCSz5J_iSJVQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "NFCz2fStSNX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2a8c7303-5733-4db8-f28b-8d82b7746109"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/albermax/innvestigate\n",
        "!pip install -q deeplift\n",
        "!git clone https://github.com/infomon/understanding_cnn\n",
        "  \n",
        "import shutil\n",
        "import os\n",
        "if not os.path.isfile(\"utils.py\"):\n",
        "  shutil.move(\"/content/understanding_cnn/utils/utils.py\", \"/content\")\n",
        "if not os.path.isfile(\"utils_imagenet.py\"):\n",
        "  shutil.move(\"/content/understanding_cnn/utils/utils_imagenet.py\", \"/content\")\n",
        "if not os.path.isdir(\"models\"):\n",
        "  shutil.move(\"/content/understanding_cnn/models\", \"/content\")\n",
        "if not os.path.isdir(\"images\"):\n",
        "  shutil.move(\"/content/understanding_cnn/data/images\", \"/content\")\n",
        "if not os.path.isfile(\"data_loader.py\"):\n",
        "  shutil.move(\"/content/understanding_cnn/data/data_loader.py\", \"/content\")\n",
        "  \n",
        "!rm -r understanding_cnn\n",
        "\n",
        "!pip install scipy==1.2.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for innvestigate (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCloning into 'understanding_cnn'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 95 (delta 31), reused 68 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (95/95), done.\n",
            "Requirement already satisfied: scipy==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FYmqnPrvSJVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kvP2z9aeSJVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "47449190-2141-4f48-af85-5c47b04746a9"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "import imp\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import keras\n",
        "import keras.backend\n",
        "import keras.models\n",
        "\n",
        "import innvestigate\n",
        "import innvestigate.applications.imagenet\n",
        "import innvestigate.utils as iutils\n",
        "\n",
        "import models.model_loader as model_loader\n",
        "import data_loader\n",
        "\n",
        "# Use utility libraries to focus on relevant iNNvestigate routines.\n",
        "eutils = imp.load_source(\"utils\", \"utils.py\")\n",
        "imgnetutils = imp.load_source(\"utils_imagenet\", \"utils_imagenet.py\")\n",
        "\n",
        "# We create many graphs, let's not run out of memory.\n",
        "if keras.backend.backend() == \"tensorflow\":\n",
        "    config = keras.backend.tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    keras.backend.set_session(keras.backend.tf.Session(config=config))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0319 21:20:55.344599 140605140694912 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "RFbx3_V-SJV-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models, data and analyzers"
      ]
    },
    {
      "metadata": {
        "id": "jKt7AuA1SJWC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We choose a set of ImageNet models:"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "RelTe1AQSJWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Choose a list of models\n",
        "netnames = [\n",
        "    # NAME                  MODEL LOADER\n",
        "    #[\"AlexNet\",             model_loader.AlexNet],\n",
        "    [\"VGG19\",               model_loader.VGG19],\n",
        "    [\"Inception_v3\",        model_loader.Inception_v3],\n",
        "    [\"Inception_Resnet_v2\", model_loader.Inception_Resnet_v2],\n",
        "    [\"Resnet_v2_152\",       model_loader.Resnet_v2_152],\n",
        "    [\"ResNeXt_101\",         model_loader.Resnet_v1_101]\n",
        "]          \n",
        "n_nets = len(netnames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIhz5BB7SJWY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following function will load a specific model, load the data in the respective format and create analyzers for this model.\n",
        "\n",
        "**For a better understanding of this part we refer to the [Comparing networks on ImagenNet](imagenet_network_comparison.ipynb) notebook, from which this code segment is adopted from.**"
      ]
    },
    {
      "metadata": {
        "id": "TgXdS-dMSJWe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_model_data_and_analyzers(loader):\n",
        "    # Load the model definition.\n",
        "    model = loader()\n",
        "\n",
        "    # Get some example test set images.\n",
        "    data = data_loader.load_from_folder(\"images\")\n",
        "\n",
        "    \n",
        "    images = [] \n",
        "    label_to_class_name = []\n",
        "    for img,label in data:\n",
        "      images.append(img)\n",
        "      label_to_class_name.append(label)\n",
        "      \n",
        "    \n",
        "    patterns = model.get_pattern()\n",
        "    input_range = (-1,1)\n",
        "\n",
        "    noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
        "\n",
        "    # Methods we use and some properties.\n",
        "    methods = [\n",
        "        # NAME                    OPT.PARAMS                POSTPROC FXN                TITLE\n",
        "        # Show input.\n",
        "        (\"input\",                 {},                       imgnetutils.image,         \"Input\"), #0\n",
        "\n",
        "        # Function\n",
        "        (\"gradient\",              {\"postprocess\": \"abs\"},   imgnetutils.graymap,       \"Gradient\"), #1\n",
        "        (\"smoothgrad\",            {\"augment_by_n\": 16,\n",
        "                                   \"noise_scale\": noise_scale,\n",
        "                                   \"postprocess\": \"square\"},imgnetutils.graymap,       \"SmoothGrad\"), #2\n",
        "\n",
        "        # Signal\n",
        "        (\"deconvnet\",             {},                       imgnetutils.bk_proj,       \"Deconvnet\"), #3\n",
        "        (\"guided_backprop\",       {},                       imgnetutils.bk_proj,       \"Guided Backprop\",), #4\n",
        "        (\"pattern.net\",           {\"patterns\": patterns},   imgnetutils.bk_proj,       \"PatternNet\"), #5\n",
        "\n",
        "        # Interaction\n",
        "        (\"pattern.attribution\",   {\"patterns\": patterns},   imgnetutils.heatmap,       \"PatternAttribution\"), #6\n",
        "        (\"deep_taylor.bounded\",   {\"low\": input_range[0],\n",
        "                                   \"high\": input_range[1]}, imgnetutils.heatmap,       \"DeepTaylor\"), #7\n",
        "        (\"input_t_gradient\",      {},                       imgnetutils.heatmap,       \"Input * Gradient\"), #8\n",
        "        (\"integrated_gradients\",  {\"reference_inputs\": input_range[0],\n",
        "                                   \"steps\": 16},            imgnetutils.heatmap,       \"Integrated Gradients\"), #9\n",
        "        (\"lrp.epsilon\",           {\"epsilon\": 1},           mnistutils.heatmap,        \"LRP-Epsilon\"), #10\n",
        "        (\"lrp.epsilon_IB\",           {\"epsilon\": 1},           mnistutils.heatmap,        \"LRP-Epsilon\"), #11\n",
        "        (\"lrp.alpha_1_beta_0\",           {},           mnistutils.heatmap,        \"LRP-Alpha1-Beta0\"), #12\n",
        "        (\"lrp.alpha_1_beta_0_IB\",           {},           mnistutils.heatmap,        \"LRP-Alpha1-Beta0 IB\"), #13\n",
        "        (\"lrp.alpha_2_beta_1\",           {},           mnistutils.heatmap,        \"LRP-Alpha2-Beta1\"), #14\n",
        "        (\"lrp.alpha_2_beta_1_IB\",           {},           mnistutils.heatmap,        \"LRP-Alpha2-Beta1 IB\"), #15\n",
        "        (\"lrp.sequential_preset_a_flat\",{\"epsilon\": 1},     imgnetutils.heatmap,       \"LRP-PresetAFlat\"), #16 \n",
        "        (\"lrp.sequential_preset_b_flat\",{\"epsilon\": 1},     imgnetutils.heatmap,       \"LRP-PresetBFlat\"), #17\n",
        "    ]\n",
        "    \n",
        "    # Select methods of your choice\n",
        "    selected_methods_indices = [0,1,6,7,8,9,11,13,15]\n",
        "    selected_methods = [methods[i] for i in selected_methods_indices]\n",
        "    print('Using method(s) \"{}\".'.format([method[0] for method in selected_methods]))\n",
        "    \n",
        "    # Create model without trailing softmax\n",
        "    model_wo_softmax = model.get_model()\n",
        "\n",
        "    # Create analyzers.\n",
        "    analyzers = []\n",
        "    for method in selected_methods:\n",
        "        try:\n",
        "            analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
        "                                                    model_wo_softmax, # model without softmax output\n",
        "                                                    **method[1])      # optional analysis parameters\n",
        "        except innvestigate.NotAnalyzeableModelException:\n",
        "            # Not all methods work with all models.\n",
        "            analyzer = None\n",
        "            print(method[3]+\" cannot be used!\")\n",
        "        analyzers.append(analyzer)\n",
        "        \n",
        "    return (images, label_to_class_name,\n",
        "            methods, model, model_wo_softmax, analyzers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtwwGzixSJWt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ]
    },
    {
      "metadata": {
        "id": "1XaJHM3HSJWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we analyze each image with the different networks and different analyzers:"
      ]
    },
    {
      "metadata": {
        "id": "c4iOXexXSJW3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "ad756aa0-f81d-4358-dfa5-8d8f564068f7"
      },
      "cell_type": "code",
      "source": [
        "analyses = {}\n",
        "texts = {}\n",
        "    \n",
        "for (netname,loader) in netnames:\n",
        "    print(\"Creating analyses for network {}.\".format(netname))\n",
        "    tmp = prepare_model_data_and_analyzers(loader)\n",
        "    (images, label_to_class_name,\n",
        "     methods, model, model_wo_softmax, analyzers) = tmp\n",
        "    \n",
        "    analysis = np.zeros([len(images), len(analyzers)]+list(model.get_image_size())+[3])\n",
        "    text = []\n",
        "    \n",
        "    channels_first = keras.backend.image_data_format() == \"channels_first\"\n",
        "    color_conversion = \"BGRtoRGB\" if model.get_color_coding() == \"BGR\" else None\n",
        "\n",
        "    for i, x in enumerate(images):\n",
        "        # Add batch axis.\n",
        "        x = x[None, :, :, :]\n",
        "        x_pp = model.preprocess_input(x)\n",
        "\n",
        "        # Predict final activations, probabilites, and label.\n",
        "        presm = model.predict_wo_softmax(x_pp)[0]\n",
        "        prob = model.predict_with_softmax(x_pp)[0]\n",
        "        y_hat = prob.argmax()\n",
        "\n",
        "        # Save prediction info:\n",
        "        text.append((\"%s\" % label_to_class_name[i],    # ground truth label\n",
        "                     \"%.2f\" % presm.max(),             # pre-softmax logits\n",
        "                     \"%.2f\" % prob.max(),              # probabilistic softmax output  \n",
        "                     \"%s\" % model.decode_predictions(prob[None,...], top=1)[0] # predicted label\n",
        "                    ))\n",
        "\n",
        "        for aidx, analyzer in enumerate(analyzers):\n",
        "            print(methods[aidx][0])\n",
        "            if methods[aidx][0] == \"input\":\n",
        "                # Do not analyze, but keep not preprocessed input.\n",
        "                a = x / 255\n",
        "            elif analyzer:\n",
        "                # Analyze.\n",
        "                a = analyzer.analyze(x_pp)\n",
        "\n",
        "                # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
        "                a = imgnetutils.postprocess(a, color_conversion, channels_first)\n",
        "                # Apply analysis postprocessing, e.g., creating a heatmap.\n",
        "                a = methods[aidx][2](a)\n",
        "            else:\n",
        "                a = np.zeros_like(x)\n",
        "            # Store the analysis.\n",
        "            analysis[i, aidx] = a[0]\n",
        "\n",
        "        analyses[netname] = analysis\n",
        "        texts[netname] = text"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating analyses for network VGG19.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0319 21:20:56.099110 140605140694912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-862971c13e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnetname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating analyses for network {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_model_data_and_analyzers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     (images, label_to_class_name,\n\u001b[1;32m      8\u001b[0m      methods, model, model_wo_softmax, analyzers) = tmp\n",
            "\u001b[0;32m<ipython-input-5-b23c107996b3>\u001b[0m in \u001b[0;36mprepare_model_data_and_analyzers\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     43\u001b[0m         (\"integrated_gradients\",  {\"reference_inputs\": input_range[0],\n\u001b[1;32m     44\u001b[0m                                    \"steps\": 16},            imgnetutils.heatmap,       \"Integrated Gradients\"), #9\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"lrp.epsilon\"\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;34m{\u001b[0m\u001b[0;34m\"epsilon\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mmnistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m\"LRP-Epsilon\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"lrp.epsilon_IB\"\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;34m{\u001b[0m\u001b[0;34m\"epsilon\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mmnistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m\"LRP-Epsilon\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"lrp.alpha_1_beta_0\"\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mmnistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m\"LRP-Alpha1-Beta0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mnistutils' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "E2auNo1OSJXO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we visualize the analysis results:"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "YxSYIxbFSJXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_images = analyses[netnames[0]].shape[0]\n",
        "\n",
        "# Prepare common labels\n",
        "col_labels = [''.join(method[3]) for method in methods]\n",
        "\n",
        "for image_index in range(n_images):\n",
        "    grid = []\n",
        "    row_labels_left = []\n",
        "    row_labels_right = []\n",
        "    \n",
        "    for netname in netnames:\n",
        "        analysis, text = analyses[netname], texts[netname]\n",
        "        # Prepare the grid as rectengular list\n",
        "        grid.append([analysis[image_index, j] for j in range(analysis.shape[1])])\n",
        "        # Prepare the labels\n",
        "        label, presm, prob, pred = zip(*text)\n",
        "        label = label[image_index]\n",
        "        row_labels_left.append(('network: {}'.format(netname),'pred: {}'.format(pred[image_index])))\n",
        "        row_labels_right.append(('logit: {}'.format(presm[image_index]),'prob: {}'.format(prob[image_index])))\n",
        "\n",
        "    # Plot the analysis.\n",
        "    print(\"Image nr. {}, true label: {}\".format(image_index, label))\n",
        "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels,\n",
        "                           file_name=os.environ.get(\"plot_file_name\", None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "quYd1UlzSJXt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This figures show the analysis regarding the *actually predicted* class as computed by the selected analyzers. Each column shows the visualized results for different analyzers and each row shows the analyses wrt to one input sample. To the left of each row, the ground truth label `label` and the predicted label `pred` are show. To the right, the model's probabilistic (softmax) output is shown as `prob` and the logit output just before the terminating softmax layer as `logit`. Note that all analyses have been performed based on the logit output (layer)."
      ]
    }
  ]
}