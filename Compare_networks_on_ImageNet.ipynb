{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compare networks on ImageNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/infomon/understanding_cnn/blob/master/Compare_networks_on_ImageNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DqkiiG7KSJVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compare networks on ImageNet"
      ]
    },
    {
      "metadata": {
        "id": "lVTelsQGSJVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook we show how one can use **iNNvestigate** to analyze the prediction of *different* ImageNet-models!\n",
        "\n",
        "This notebook is an extension of the [Comparing networks on ImagenNet](imagenet_network_comparison.ipynb) notebook.\n"
      ]
    },
    {
      "metadata": {
        "id": "gCSz5J_iSJVQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Innvestigate Toolbox is installed. The toolbox contains multiple visualization methods being used in this experiment.\n",
        "Also some needed helper files are clone from the understanding_cnn repository. The whole folder is removed, after moving all needed helpers to the /content/ directory"
      ]
    },
    {
      "metadata": {
        "id": "NFCz2fStSNX2",
        "colab_type": "code",
        "outputId": "789e6b89-d14d-41bb-9d37-e358fd8ec4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/albermax/innvestigate\n",
        "!pip install -q deeplift\n",
        "!git clone https://github.com/infomon/understanding_cnn\n",
        "  \n",
        "import shutil\n",
        "import os\n",
        "if not os.path.isfile(\"utils.py\"):\n",
        "  shutil.move(\"/content/understanding_cnn/utils/utils.py\", \"/content\")\n",
        "if not os.path.isfile(\"utils_imagenet.py\"):\n",
        "  shutil.move(\"/content/understanding_cnn/utils/utils_imagenet.py\", \"/content\")\n",
        "if not os.path.isdir(\"models\"):\n",
        "  shutil.move(\"/content/understanding_cnn/models\", \"/content\")\n",
        "if not os.path.isdir(\"images\"):\n",
        "  shutil.move(\"/content/understanding_cnn/data/images\", \"/content\")\n",
        "if not os.path.isfile(\"data_loader.py\"):\n",
        "  shutil.move(\"/content/understanding_cnn/data/data_loader.py\", \"/content\")\n",
        "  \n",
        "!rm -r understanding_cnn\n",
        "\n",
        "!pip install scipy==1.2.0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for innvestigate (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCloning into 'understanding_cnn'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 135 (delta 54), reused 85 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (135/135), 15.24 MiB | 7.53 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "Requirement already satisfied: scipy==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FYmqnPrvSJVV",
        "colab_type": "code",
        "outputId": "b10e2632-71c0-434c-9f69-63811c679b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kvP2z9aeSJVk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "import imp\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import keras\n",
        "import keras.backend\n",
        "import keras.models\n",
        "\n",
        "import innvestigate\n",
        "import innvestigate.applications.imagenet\n",
        "import innvestigate.utils as iutils\n",
        "\n",
        "import models.model_loader as model_loader\n",
        "import data_loader\n",
        "\n",
        "# Use utility libraries to focus on relevant iNNvestigate routines.\n",
        "eutils = imp.load_source(\"utils\", \"utils.py\")\n",
        "imgnetutils = imp.load_source(\"utils_imagenet\", \"utils_imagenet.py\")\n",
        "\n",
        "# We create many graphs, let's not run out of memory.\n",
        "if keras.backend.backend() == \"tensorflow\":\n",
        "    config = keras.backend.tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    keras.backend.set_session(keras.backend.tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RFbx3_V-SJV-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models, data and analyzers"
      ]
    },
    {
      "metadata": {
        "id": "jKt7AuA1SJWC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We choose a set of ImageNet models:"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "RelTe1AQSJWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Choose a list of models\n",
        "netnames = [\n",
        "    # NAME                  MODEL LOADER\n",
        "    #[\"AlexNet\",             model_loader.AlexNet],\n",
        "    #[\"VGG19\",               model_loader.VGG19],\n",
        "    #[\"Inception_v3\",        model_loader.Inception_v3],\n",
        "    [\"Inception_Resnet_v2\", model_loader.Inception_Resnet_v2],\n",
        "    [\"Resnet_v2_152\",       model_loader.Resnet_v2_152],\n",
        "    [\"ResNeXt_101\",         model_loader.Resnet_v1_101]\n",
        "]          \n",
        "n_nets = len(netnames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIhz5BB7SJWY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following function will load a specific model, load the data in the respective format and create analyzers for this model.\n",
        "\n",
        "**For a better understanding of this part we refer to the [Comparing networks on ImagenNet](imagenet_network_comparison.ipynb) notebook, from which this code segment is adopted from.**"
      ]
    },
    {
      "metadata": {
        "id": "TgXdS-dMSJWe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_model_data_and_analyzers(loader):\n",
        "    # Load the model definition.\n",
        "    model = loader()\n",
        "\n",
        "    # Get some example test set images.\n",
        "    data = data_loader.load_from_folder(\"images\",model.get_image_size())\n",
        "\n",
        "    \n",
        "    images = [] \n",
        "    label_to_class_name = []\n",
        "    for img,label in data:\n",
        "      images.append(img)\n",
        "      label_to_class_name.append(label)\n",
        "      \n",
        "    \n",
        "    patterns = model.get_patterns()\n",
        "    input_range = (-1,1)\n",
        "\n",
        "    noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
        "\n",
        "    # Methods we use and some properties.\n",
        "    methods = [\n",
        "        # NAME                    OPT.PARAMS                POSTPROC FXN                TITLE\n",
        "        # Show input.\n",
        "        (\"input\",                 {},                       imgnetutils.image,         \"Input\"), #0\n",
        "\n",
        "        # Function\n",
        "        (\"gradient\",              {\"postprocess\": \"abs\"},   imgnetutils.graymap,       \"Gradient\"), #1\n",
        "        (\"smoothgrad\",            {\"augment_by_n\": 16,\n",
        "                                   \"noise_scale\": noise_scale,\n",
        "                                   \"postprocess\": \"square\"},imgnetutils.graymap,       \"SmoothGrad\"), #2\n",
        "\n",
        "        # Signal\n",
        "        (\"deconvnet\",             {},                       imgnetutils.bk_proj,       \"Deconvnet\"), #3\n",
        "        (\"guided_backprop\",       {},                       imgnetutils.bk_proj,       \"Guided Backprop\",), #4\n",
        "        (\"pattern.net\",           {\"patterns\": patterns},   imgnetutils.bk_proj,       \"PatternNet\"), #5\n",
        "\n",
        "        # Interaction\n",
        "        (\"pattern.attribution\",   {\"patterns\": patterns},   imgnetutils.heatmap,       \"PatternAttribution\"), #6\n",
        "        (\"deep_taylor.bounded\",   {\"low\": input_range[0],\n",
        "                                   \"high\": input_range[1]}, imgnetutils.heatmap,       \"DeepTaylor\"), #7\n",
        "        (\"input_t_gradient\",      {},                       imgnetutils.heatmap,       \"Input * Gradient\"), #8\n",
        "        (\"integrated_gradients\",  {\"reference_inputs\": input_range[0],\n",
        "                                   \"steps\": 16},            imgnetutils.heatmap,       \"Integrated Gradients\"), #9\n",
        "        (\"lrp.epsilon\",           {\"epsilon\": 1},           imgnetutils.heatmap,        \"LRP-Epsilon\"), #10\n",
        "        (\"lrp.epsilon_IB\",           {\"epsilon\": 1},           imgnetutils.heatmap,        \"LRP-Epsilon IB\"), #11\n",
        "        (\"lrp.alpha_1_beta_0\",           {},           imgnetutils.heatmap,        \"LRP-Alpha1-Beta0\"), #12\n",
        "        (\"lrp.alpha_1_beta_0_IB\",           {},           imgnetutils.heatmap,        \"LRP-Alpha1-Beta0 IB\"), #13\n",
        "        (\"lrp.alpha_2_beta_1\",           {},           imgnetutils.heatmap,        \"LRP-Alpha2-Beta1\"), #14\n",
        "        (\"lrp.alpha_2_beta_1_IB\",           {},           imgnetutils.heatmap,        \"LRP-Alpha2-Beta1 IB\"), #15\n",
        "        (\"lrp.sequential_preset_a_flat\",{\"epsilon\": 1},     imgnetutils.heatmap,       \"LRP-PresetAFlat\"), #16 \n",
        "        (\"lrp.sequential_preset_b_flat\",{\"epsilon\": 1},     imgnetutils.heatmap,       \"LRP-PresetBFlat\"), #17\n",
        "    ]\n",
        "    \n",
        "    # Select methods of your choice\n",
        "    selected_methods_indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
        "    selected_methods = [methods[i] for i in selected_methods_indices]\n",
        "    print('Using method(s) \"{}\".'.format([method[0] for method in selected_methods]))\n",
        "    \n",
        "    # Create model without trailing softmax\n",
        "    model_wo_softmax = model.get_model()\n",
        "\n",
        "    # Create analyzers.\n",
        "    analyzers = []\n",
        "    for method in selected_methods:\n",
        "        try:\n",
        "            analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
        "                                                    model_wo_softmax, # model without softmax output\n",
        "                                                    **method[1])      # optional analysis parameters\n",
        "        except innvestigate.NotAnalyzeableModelException:\n",
        "            # Not all methods work with all models.\n",
        "            analyzer = None\n",
        "            print(method[3]+\" cannot be used!\")\n",
        "        analyzers.append(analyzer)\n",
        "        \n",
        "    return (images, label_to_class_name,\n",
        "            selected_methods, model, model_wo_softmax, analyzers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtwwGzixSJWt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ]
    },
    {
      "metadata": {
        "id": "1XaJHM3HSJWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we analyze each image with the different networks and different analyzers:"
      ]
    },
    {
      "metadata": {
        "id": "c4iOXexXSJW3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6582
        },
        "outputId": "217ee3af-fb2a-4b7e-80ff-bc3526ccf34b"
      },
      "cell_type": "code",
      "source": [
        "analyses = {}\n",
        "texts = {}\n",
        "    \n",
        "for (netname,loader) in netnames:\n",
        "    print(\"Creating analyses for network {}.\".format(netname))\n",
        "    tmp = prepare_model_data_and_analyzers(loader)\n",
        "    (images, label_to_class_name,\n",
        "     methods, model, model_wo_softmax, analyzers) = tmp\n",
        "    \n",
        "    analysis = np.zeros([len(images), len(analyzers)]+list(model.get_image_size())+[3])\n",
        "    text = []\n",
        "    \n",
        "    channels_first = keras.backend.image_data_format() == \"channels_first\"\n",
        "    color_conversion = \"BGRtoRGB\" if model.get_color_coding() == \"BGR\" else None\n",
        "\n",
        "    for i, x in enumerate(images):\n",
        "        # Add batch axis.\n",
        "        x_pp = model.preprocess_input(x)\n",
        "\n",
        "        # Predict final activations, probabilites, and label.\n",
        "        presm = model.predict_wo_softmax(x_pp)[0]\n",
        "        prob = model.predict_with_softmax(x_pp)[0]\n",
        "        y_hat = prob.argmax()\n",
        "\n",
        "        # Save prediction info:\n",
        "        text.append((\"%s\" % label_to_class_name[i],    # ground truth label\n",
        "                     \"%.2f\" % presm.max(),             # pre-softmax logits\n",
        "                     \"%.2f\" % prob.max(),              # probabilistic softmax output  \n",
        "                     \"%s\" % model.decode_predictions(prob[None,...], top=1)[0] # predicted label\n",
        "                    ))\n",
        "\n",
        "        for aidx, analyzer in enumerate(analyzers):\n",
        "            print(methods[aidx][0]+\" for image with label \"+label_to_class_name[i])\n",
        "            if methods[aidx][0] == \"input\":\n",
        "                # Do not analyze, but keep not preprocessed input.\n",
        "                a = x / 255\n",
        "            elif analyzer:\n",
        "                # Analyze.\n",
        "                a = analyzer.analyze(x_pp)\n",
        "\n",
        "                # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
        "                a = imgnetutils.postprocess(a, color_conversion, channels_first)\n",
        "                # Apply analysis postprocessing, e.g., creating a heatmap.\n",
        "                a = methods[aidx][2](a)\n",
        "            else:\n",
        "                a = np.zeros_like(x)\n",
        "            # Store the analysis.\n",
        "            analysis[i, aidx] = a[0]\n",
        "\n",
        "        analyses[netname] = analysis\n",
        "        texts[netname] = text\n",
        "        np.save(\"analysis_\"+netname+\".npy\",analysis)\n",
        "        np.save(\"text_\"+netname+\".npy\",text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating analyses for network Inception_Resnet_v2.\n",
            "Using method(s) \"['input', 'gradient', 'smoothgrad', 'deconvnet', 'guided_backprop', 'pattern.net', 'pattern.attribution', 'deep_taylor.bounded', 'input_t_gradient', 'integrated_gradients', 'lrp.epsilon', 'lrp.epsilon_IB', 'lrp.alpha_1_beta_0', 'lrp.alpha_1_beta_0_IB', 'lrp.alpha_2_beta_1', 'lrp.alpha_2_beta_1_IB', 'lrp.sequential_preset_a_flat', 'lrp.sequential_preset_b_flat']\".\n",
            "Input cannot be used!\n",
            "Gradient cannot be used!\n",
            "SmoothGrad cannot be used!\n",
            "Deconvnet cannot be used!\n",
            "Guided Backprop cannot be used!\n",
            "PatternNet cannot be used!\n",
            "PatternAttribution cannot be used!\n",
            "DeepTaylor cannot be used!\n",
            "Input * Gradient cannot be used!\n",
            "Integrated Gradients cannot be used!\n",
            "LRP-Epsilon cannot be used!\n",
            "LRP-Epsilon IB cannot be used!\n",
            "LRP-Alpha1-Beta0 cannot be used!\n",
            "LRP-Alpha1-Beta0 IB cannot be used!\n",
            "LRP-Alpha2-Beta1 cannot be used!\n",
            "LRP-Alpha2-Beta1 IB cannot be used!\n",
            "LRP-PresetAFlat cannot be used!\n",
            "LRP-PresetBFlat cannot be used!\n",
            "input for image with label dog\n",
            "gradient for image with label dog\n",
            "smoothgrad for image with label dog\n",
            "deconvnet for image with label dog\n",
            "guided_backprop for image with label dog\n",
            "pattern.net for image with label dog\n",
            "pattern.attribution for image with label dog\n",
            "deep_taylor.bounded for image with label dog\n",
            "input_t_gradient for image with label dog\n",
            "integrated_gradients for image with label dog\n",
            "lrp.epsilon for image with label dog\n",
            "lrp.epsilon_IB for image with label dog\n",
            "lrp.alpha_1_beta_0 for image with label dog\n",
            "lrp.alpha_1_beta_0_IB for image with label dog\n",
            "lrp.alpha_2_beta_1 for image with label dog\n",
            "lrp.alpha_2_beta_1_IB for image with label dog\n",
            "lrp.sequential_preset_a_flat for image with label dog\n",
            "lrp.sequential_preset_b_flat for image with label dog\n",
            "input for image with label bell pepper\n",
            "gradient for image with label bell pepper\n",
            "smoothgrad for image with label bell pepper\n",
            "deconvnet for image with label bell pepper\n",
            "guided_backprop for image with label bell pepper\n",
            "pattern.net for image with label bell pepper\n",
            "pattern.attribution for image with label bell pepper\n",
            "deep_taylor.bounded for image with label bell pepper\n",
            "input_t_gradient for image with label bell pepper\n",
            "integrated_gradients for image with label bell pepper\n",
            "lrp.epsilon for image with label bell pepper\n",
            "lrp.epsilon_IB for image with label bell pepper\n",
            "lrp.alpha_1_beta_0 for image with label bell pepper\n",
            "lrp.alpha_1_beta_0_IB for image with label bell pepper\n",
            "lrp.alpha_2_beta_1 for image with label bell pepper\n",
            "lrp.alpha_2_beta_1_IB for image with label bell pepper\n",
            "lrp.sequential_preset_a_flat for image with label bell pepper\n",
            "lrp.sequential_preset_b_flat for image with label bell pepper\n",
            "input for image with label airplane\n",
            "gradient for image with label airplane\n",
            "smoothgrad for image with label airplane\n",
            "deconvnet for image with label airplane\n",
            "guided_backprop for image with label airplane\n",
            "pattern.net for image with label airplane\n",
            "pattern.attribution for image with label airplane\n",
            "deep_taylor.bounded for image with label airplane\n",
            "input_t_gradient for image with label airplane\n",
            "integrated_gradients for image with label airplane\n",
            "lrp.epsilon for image with label airplane\n",
            "lrp.epsilon_IB for image with label airplane\n",
            "lrp.alpha_1_beta_0 for image with label airplane\n",
            "lrp.alpha_1_beta_0_IB for image with label airplane\n",
            "lrp.alpha_2_beta_1 for image with label airplane\n",
            "lrp.alpha_2_beta_1_IB for image with label airplane\n",
            "lrp.sequential_preset_a_flat for image with label airplane\n",
            "lrp.sequential_preset_b_flat for image with label airplane\n",
            "input for image with label leopard\n",
            "gradient for image with label leopard\n",
            "smoothgrad for image with label leopard\n",
            "deconvnet for image with label leopard\n",
            "guided_backprop for image with label leopard\n",
            "pattern.net for image with label leopard\n",
            "pattern.attribution for image with label leopard\n",
            "deep_taylor.bounded for image with label leopard\n",
            "input_t_gradient for image with label leopard\n",
            "integrated_gradients for image with label leopard\n",
            "lrp.epsilon for image with label leopard\n",
            "lrp.epsilon_IB for image with label leopard\n",
            "lrp.alpha_1_beta_0 for image with label leopard\n",
            "lrp.alpha_1_beta_0_IB for image with label leopard\n",
            "lrp.alpha_2_beta_1 for image with label leopard\n",
            "lrp.alpha_2_beta_1_IB for image with label leopard\n",
            "lrp.sequential_preset_a_flat for image with label leopard\n",
            "lrp.sequential_preset_b_flat for image with label leopard\n",
            "input for image with label husky\n",
            "gradient for image with label husky\n",
            "smoothgrad for image with label husky\n",
            "deconvnet for image with label husky\n",
            "guided_backprop for image with label husky\n",
            "pattern.net for image with label husky\n",
            "pattern.attribution for image with label husky\n",
            "deep_taylor.bounded for image with label husky\n",
            "input_t_gradient for image with label husky\n",
            "integrated_gradients for image with label husky\n",
            "lrp.epsilon for image with label husky\n",
            "lrp.epsilon_IB for image with label husky\n",
            "lrp.alpha_1_beta_0 for image with label husky\n",
            "lrp.alpha_1_beta_0_IB for image with label husky\n",
            "lrp.alpha_2_beta_1 for image with label husky\n",
            "lrp.alpha_2_beta_1_IB for image with label husky\n",
            "lrp.sequential_preset_a_flat for image with label husky\n",
            "lrp.sequential_preset_b_flat for image with label husky\n",
            "input for image with label tabby_cat\n",
            "gradient for image with label tabby_cat\n",
            "smoothgrad for image with label tabby_cat\n",
            "deconvnet for image with label tabby_cat\n",
            "guided_backprop for image with label tabby_cat\n",
            "pattern.net for image with label tabby_cat\n",
            "pattern.attribution for image with label tabby_cat\n",
            "deep_taylor.bounded for image with label tabby_cat\n",
            "input_t_gradient for image with label tabby_cat\n",
            "integrated_gradients for image with label tabby_cat\n",
            "lrp.epsilon for image with label tabby_cat\n",
            "lrp.epsilon_IB for image with label tabby_cat\n",
            "lrp.alpha_1_beta_0 for image with label tabby_cat\n",
            "lrp.alpha_1_beta_0_IB for image with label tabby_cat\n",
            "lrp.alpha_2_beta_1 for image with label tabby_cat\n",
            "lrp.alpha_2_beta_1_IB for image with label tabby_cat\n",
            "lrp.sequential_preset_a_flat for image with label tabby_cat\n",
            "lrp.sequential_preset_b_flat for image with label tabby_cat\n",
            "input for image with label gruffed grouse\n",
            "gradient for image with label gruffed grouse\n",
            "smoothgrad for image with label gruffed grouse\n",
            "deconvnet for image with label gruffed grouse\n",
            "guided_backprop for image with label gruffed grouse\n",
            "pattern.net for image with label gruffed grouse\n",
            "pattern.attribution for image with label gruffed grouse\n",
            "deep_taylor.bounded for image with label gruffed grouse\n",
            "input_t_gradient for image with label gruffed grouse\n",
            "integrated_gradients for image with label gruffed grouse\n",
            "lrp.epsilon for image with label gruffed grouse\n",
            "lrp.epsilon_IB for image with label gruffed grouse\n",
            "lrp.alpha_1_beta_0 for image with label gruffed grouse\n",
            "lrp.alpha_1_beta_0_IB for image with label gruffed grouse\n",
            "lrp.alpha_2_beta_1 for image with label gruffed grouse\n",
            "lrp.alpha_2_beta_1_IB for image with label gruffed grouse\n",
            "lrp.sequential_preset_a_flat for image with label gruffed grouse\n",
            "lrp.sequential_preset_b_flat for image with label gruffed grouse\n",
            "input for image with label accordion\n",
            "gradient for image with label accordion\n",
            "smoothgrad for image with label accordion\n",
            "deconvnet for image with label accordion\n",
            "guided_backprop for image with label accordion\n",
            "pattern.net for image with label accordion\n",
            "pattern.attribution for image with label accordion\n",
            "deep_taylor.bounded for image with label accordion\n",
            "input_t_gradient for image with label accordion\n",
            "integrated_gradients for image with label accordion\n",
            "lrp.epsilon for image with label accordion\n",
            "lrp.epsilon_IB for image with label accordion\n",
            "lrp.alpha_1_beta_0 for image with label accordion\n",
            "lrp.alpha_1_beta_0_IB for image with label accordion\n",
            "lrp.alpha_2_beta_1 for image with label accordion\n",
            "lrp.alpha_2_beta_1_IB for image with label accordion\n",
            "lrp.sequential_preset_a_flat for image with label accordion\n",
            "lrp.sequential_preset_b_flat for image with label accordion\n",
            "input for image with label african elephant\n",
            "gradient for image with label african elephant\n",
            "smoothgrad for image with label african elephant\n",
            "deconvnet for image with label african elephant\n",
            "guided_backprop for image with label african elephant\n",
            "pattern.net for image with label african elephant\n",
            "pattern.attribution for image with label african elephant\n",
            "deep_taylor.bounded for image with label african elephant\n",
            "input_t_gradient for image with label african elephant\n",
            "integrated_gradients for image with label african elephant\n",
            "lrp.epsilon for image with label african elephant\n",
            "lrp.epsilon_IB for image with label african elephant\n",
            "lrp.alpha_1_beta_0 for image with label african elephant\n",
            "lrp.alpha_1_beta_0_IB for image with label african elephant\n",
            "lrp.alpha_2_beta_1 for image with label african elephant\n",
            "lrp.alpha_2_beta_1_IB for image with label african elephant\n",
            "lrp.sequential_preset_a_flat for image with label african elephant\n",
            "lrp.sequential_preset_b_flat for image with label african elephant\n",
            "input for image with label subway train\n",
            "gradient for image with label subway train\n",
            "smoothgrad for image with label subway train\n",
            "deconvnet for image with label subway train\n",
            "guided_backprop for image with label subway train\n",
            "pattern.net for image with label subway train\n",
            "pattern.attribution for image with label subway train\n",
            "deep_taylor.bounded for image with label subway train\n",
            "input_t_gradient for image with label subway train\n",
            "integrated_gradients for image with label subway train\n",
            "lrp.epsilon for image with label subway train\n",
            "lrp.epsilon_IB for image with label subway train\n",
            "lrp.alpha_1_beta_0 for image with label subway train\n",
            "lrp.alpha_1_beta_0_IB for image with label subway train\n",
            "lrp.alpha_2_beta_1 for image with label subway train\n",
            "lrp.alpha_2_beta_1_IB for image with label subway train\n",
            "lrp.sequential_preset_a_flat for image with label subway train\n",
            "lrp.sequential_preset_b_flat for image with label subway train\n",
            "Creating analyses for network Resnet_v2_152.\n",
            "Using method(s) \"['input', 'gradient', 'smoothgrad', 'deconvnet', 'guided_backprop', 'pattern.net', 'pattern.attribution', 'deep_taylor.bounded', 'input_t_gradient', 'integrated_gradients', 'lrp.epsilon', 'lrp.epsilon_IB', 'lrp.alpha_1_beta_0', 'lrp.alpha_1_beta_0_IB', 'lrp.alpha_2_beta_1', 'lrp.alpha_2_beta_1_IB', 'lrp.sequential_preset_a_flat', 'lrp.sequential_preset_b_flat']\".\n",
            "PatternNet cannot be used!\n",
            "PatternAttribution cannot be used!\n",
            "input for image with label dog\n",
            "gradient for image with label dog\n",
            "smoothgrad for image with label dog\n",
            "deconvnet for image with label dog\n",
            "guided_backprop for image with label dog\n",
            "pattern.net for image with label dog\n",
            "pattern.attribution for image with label dog\n",
            "deep_taylor.bounded for image with label dog\n",
            "input_t_gradient for image with label dog\n",
            "integrated_gradients for image with label dog\n",
            "lrp.epsilon for image with label dog\n",
            "lrp.epsilon_IB for image with label dog\n",
            "lrp.alpha_1_beta_0 for image with label dog\n",
            "lrp.alpha_1_beta_0_IB for image with label dog\n",
            "lrp.alpha_2_beta_1 for image with label dog\n",
            "lrp.alpha_2_beta_1_IB for image with label dog\n",
            "lrp.sequential_preset_a_flat for image with label dog\n",
            "lrp.sequential_preset_b_flat for image with label dog\n",
            "input for image with label bell pepper\n",
            "gradient for image with label bell pepper\n",
            "smoothgrad for image with label bell pepper\n",
            "deconvnet for image with label bell pepper\n",
            "guided_backprop for image with label bell pepper\n",
            "pattern.net for image with label bell pepper\n",
            "pattern.attribution for image with label bell pepper\n",
            "deep_taylor.bounded for image with label bell pepper\n",
            "input_t_gradient for image with label bell pepper\n",
            "integrated_gradients for image with label bell pepper\n",
            "lrp.epsilon for image with label bell pepper\n",
            "lrp.epsilon_IB for image with label bell pepper\n",
            "lrp.alpha_1_beta_0 for image with label bell pepper\n",
            "lrp.alpha_1_beta_0_IB for image with label bell pepper\n",
            "lrp.alpha_2_beta_1 for image with label bell pepper\n",
            "lrp.alpha_2_beta_1_IB for image with label bell pepper\n",
            "lrp.sequential_preset_a_flat for image with label bell pepper\n",
            "lrp.sequential_preset_b_flat for image with label bell pepper\n",
            "input for image with label airplane\n",
            "gradient for image with label airplane\n",
            "smoothgrad for image with label airplane\n",
            "deconvnet for image with label airplane\n",
            "guided_backprop for image with label airplane\n",
            "pattern.net for image with label airplane\n",
            "pattern.attribution for image with label airplane\n",
            "deep_taylor.bounded for image with label airplane\n",
            "input_t_gradient for image with label airplane\n",
            "integrated_gradients for image with label airplane\n",
            "lrp.epsilon for image with label airplane\n",
            "lrp.epsilon_IB for image with label airplane\n",
            "lrp.alpha_1_beta_0 for image with label airplane\n",
            "lrp.alpha_1_beta_0_IB for image with label airplane\n",
            "lrp.alpha_2_beta_1 for image with label airplane\n",
            "lrp.alpha_2_beta_1_IB for image with label airplane\n",
            "lrp.sequential_preset_a_flat for image with label airplane\n",
            "lrp.sequential_preset_b_flat for image with label airplane\n",
            "input for image with label leopard\n",
            "gradient for image with label leopard\n",
            "smoothgrad for image with label leopard\n",
            "deconvnet for image with label leopard\n",
            "guided_backprop for image with label leopard\n",
            "pattern.net for image with label leopard\n",
            "pattern.attribution for image with label leopard\n",
            "deep_taylor.bounded for image with label leopard\n",
            "input_t_gradient for image with label leopard\n",
            "integrated_gradients for image with label leopard\n",
            "lrp.epsilon for image with label leopard\n",
            "lrp.epsilon_IB for image with label leopard\n",
            "lrp.alpha_1_beta_0 for image with label leopard\n",
            "lrp.alpha_1_beta_0_IB for image with label leopard\n",
            "lrp.alpha_2_beta_1 for image with label leopard\n",
            "lrp.alpha_2_beta_1_IB for image with label leopard\n",
            "lrp.sequential_preset_a_flat for image with label leopard\n",
            "lrp.sequential_preset_b_flat for image with label leopard\n",
            "input for image with label husky\n",
            "gradient for image with label husky\n",
            "smoothgrad for image with label husky\n",
            "deconvnet for image with label husky\n",
            "guided_backprop for image with label husky\n",
            "pattern.net for image with label husky\n",
            "pattern.attribution for image with label husky\n",
            "deep_taylor.bounded for image with label husky\n",
            "input_t_gradient for image with label husky\n",
            "integrated_gradients for image with label husky\n",
            "lrp.epsilon for image with label husky\n",
            "lrp.epsilon_IB for image with label husky\n",
            "lrp.alpha_1_beta_0 for image with label husky\n",
            "lrp.alpha_1_beta_0_IB for image with label husky\n",
            "lrp.alpha_2_beta_1 for image with label husky\n",
            "lrp.alpha_2_beta_1_IB for image with label husky\n",
            "lrp.sequential_preset_a_flat for image with label husky\n",
            "lrp.sequential_preset_b_flat for image with label husky\n",
            "input for image with label tabby_cat\n",
            "gradient for image with label tabby_cat\n",
            "smoothgrad for image with label tabby_cat\n",
            "deconvnet for image with label tabby_cat\n",
            "guided_backprop for image with label tabby_cat\n",
            "pattern.net for image with label tabby_cat\n",
            "pattern.attribution for image with label tabby_cat\n",
            "deep_taylor.bounded for image with label tabby_cat\n",
            "input_t_gradient for image with label tabby_cat\n",
            "integrated_gradients for image with label tabby_cat\n",
            "lrp.epsilon for image with label tabby_cat\n",
            "lrp.epsilon_IB for image with label tabby_cat\n",
            "lrp.alpha_1_beta_0 for image with label tabby_cat\n",
            "lrp.alpha_1_beta_0_IB for image with label tabby_cat\n",
            "lrp.alpha_2_beta_1 for image with label tabby_cat\n",
            "lrp.alpha_2_beta_1_IB for image with label tabby_cat\n",
            "lrp.sequential_preset_a_flat for image with label tabby_cat\n",
            "lrp.sequential_preset_b_flat for image with label tabby_cat\n",
            "input for image with label gruffed grouse\n",
            "gradient for image with label gruffed grouse\n",
            "smoothgrad for image with label gruffed grouse\n",
            "deconvnet for image with label gruffed grouse\n",
            "guided_backprop for image with label gruffed grouse\n",
            "pattern.net for image with label gruffed grouse\n",
            "pattern.attribution for image with label gruffed grouse\n",
            "deep_taylor.bounded for image with label gruffed grouse\n",
            "input_t_gradient for image with label gruffed grouse\n",
            "integrated_gradients for image with label gruffed grouse\n",
            "lrp.epsilon for image with label gruffed grouse\n",
            "lrp.epsilon_IB for image with label gruffed grouse\n",
            "lrp.alpha_1_beta_0 for image with label gruffed grouse\n",
            "lrp.alpha_1_beta_0_IB for image with label gruffed grouse\n",
            "lrp.alpha_2_beta_1 for image with label gruffed grouse\n",
            "lrp.alpha_2_beta_1_IB for image with label gruffed grouse\n",
            "lrp.sequential_preset_a_flat for image with label gruffed grouse\n",
            "lrp.sequential_preset_b_flat for image with label gruffed grouse\n",
            "input for image with label accordion\n",
            "gradient for image with label accordion\n",
            "smoothgrad for image with label accordion\n",
            "deconvnet for image with label accordion\n",
            "guided_backprop for image with label accordion\n",
            "pattern.net for image with label accordion\n",
            "pattern.attribution for image with label accordion\n",
            "deep_taylor.bounded for image with label accordion\n",
            "input_t_gradient for image with label accordion\n",
            "integrated_gradients for image with label accordion\n",
            "lrp.epsilon for image with label accordion\n",
            "lrp.epsilon_IB for image with label accordion\n",
            "lrp.alpha_1_beta_0 for image with label accordion\n",
            "lrp.alpha_1_beta_0_IB for image with label accordion\n",
            "lrp.alpha_2_beta_1 for image with label accordion\n",
            "lrp.alpha_2_beta_1_IB for image with label accordion\n",
            "lrp.sequential_preset_a_flat for image with label accordion\n",
            "lrp.sequential_preset_b_flat for image with label accordion\n",
            "input for image with label african elephant\n",
            "gradient for image with label african elephant\n",
            "smoothgrad for image with label african elephant\n",
            "deconvnet for image with label african elephant\n",
            "guided_backprop for image with label african elephant\n",
            "pattern.net for image with label african elephant\n",
            "pattern.attribution for image with label african elephant\n",
            "deep_taylor.bounded for image with label african elephant\n",
            "input_t_gradient for image with label african elephant\n",
            "integrated_gradients for image with label african elephant\n",
            "lrp.epsilon for image with label african elephant\n",
            "lrp.epsilon_IB for image with label african elephant\n",
            "lrp.alpha_1_beta_0 for image with label african elephant\n",
            "lrp.alpha_1_beta_0_IB for image with label african elephant\n",
            "lrp.alpha_2_beta_1 for image with label african elephant\n",
            "lrp.alpha_2_beta_1_IB for image with label african elephant\n",
            "lrp.sequential_preset_a_flat for image with label african elephant\n",
            "lrp.sequential_preset_b_flat for image with label african elephant\n",
            "input for image with label subway train\n",
            "gradient for image with label subway train\n",
            "smoothgrad for image with label subway train\n",
            "deconvnet for image with label subway train\n",
            "guided_backprop for image with label subway train\n",
            "pattern.net for image with label subway train\n",
            "pattern.attribution for image with label subway train\n",
            "deep_taylor.bounded for image with label subway train\n",
            "input_t_gradient for image with label subway train\n",
            "integrated_gradients for image with label subway train\n",
            "lrp.epsilon for image with label subway train\n",
            "lrp.epsilon_IB for image with label subway train\n",
            "lrp.alpha_1_beta_0 for image with label subway train\n",
            "lrp.alpha_1_beta_0_IB for image with label subway train\n",
            "lrp.alpha_2_beta_1 for image with label subway train\n",
            "lrp.alpha_2_beta_1_IB for image with label subway train\n",
            "lrp.sequential_preset_a_flat for image with label subway train\n",
            "lrp.sequential_preset_b_flat for image with label subway train\n",
            "Creating analyses for network ResNeXt_101.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E2auNo1OSJXO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we visualize the analysis results:"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "YxSYIxbFSJXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_images = analyses[netnames[0][0]].shape[0]\n",
        "\n",
        "# Prepare common labels\n",
        "col_labels = [''.join(method[3]) for method in methods]\n",
        "\n",
        "for image_index in range(n_images):\n",
        "    grid = []\n",
        "    row_labels_left = []\n",
        "    row_labels_right = []\n",
        "    \n",
        "    for netname,_ in netnames:\n",
        "        analysis, text = analyses[netname], texts[netname]\n",
        "        # Prepare the grid as rectengular list\n",
        "        grid.append([analysis[image_index, j] for j in range(analysis.shape[1])])\n",
        "        # Prepare the labels\n",
        "        label, presm, prob, pred = zip(*text)\n",
        "        label = label[image_index]\n",
        "        row_labels_left.append(('network: {}'.format(netname),'pred: {}'.format(pred[image_index])))\n",
        "        row_labels_right.append(('logit: {}'.format(presm[image_index]),'prob: {}'.format(prob[image_index])))\n",
        "\n",
        "    # Plot the analysis.\n",
        "    print(\"Image nr. {}, true label: {}\".format(image_index, label))\n",
        "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels,\n",
        "                           file_name=os.environ.get(\"plot_file_name\", None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "quYd1UlzSJXt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This figures show the analysis regarding the *actually predicted* class as computed by the selected analyzers. Each column shows the visualized results for different analyzers and each row shows the analyses wrt to one input sample. To the left of each row, the ground truth label `label` and the predicted label `pred` are show. To the right, the model's probabilistic (softmax) output is shown as `prob` and the logit output just before the terminating softmax layer as `logit`. Note that all analyses have been performed based on the logit output (layer)."
      ]
    }
  ]
}